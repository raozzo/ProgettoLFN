{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Approximated Closeness Centrality",
   "id": "1990977e9da64fa6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Libraries import & graph retrieval",
   "id": "c326893dd7adb579"
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-13T23:58:39.727133Z",
     "start_time": "2025-12-13T23:58:35.503086Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pickle               # to read the Amazon DiGraph\n",
    "import networkx as nx       # to work with graphs\n",
    "\n",
    "graph_path = \"../data/processed/amazon_graph.pickle\"\n",
    "\n",
    "with open(graph_path, \"rb\") as f:\n",
    "    G = pickle.load(f)"
   ],
   "id": "b29d97a71f269d3b",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "## Hyperball Algorithm\n",
    "\n",
    "HyperBall è l'algoritmo che usa i contatori HLL per calcolare la centralità su tutto il grafo in modo efficiente. L'idea geniale è che non serve fare una visita (BFS) per ogni nodo. Si possono \"muovere\" i contatori.\n",
    "\n",
    "Il Funzionamento Passo-Passo:\n",
    "1. Inizializzazione ($t=0$): Ogni nodo ha un contatore HLL che contiene solo se stesso. Quindi ogni nodo sa di poter raggiungere 1 persona (se stesso) a distanza 0.\n",
    "2. Iterazione ($t=1, 2, \\dots$): Immagina che ogni nodo dica ai suoi vicini: \"Ehi, questi sono tutti i nodi che io so raggiungere\". In termini tecnici: il contatore HLL di un nodo $x$ viene aggiornato facendone l'unione con i contatori HLL dei suoi vicini. Grazie alla matematica degli HLL, l'unione è un'operazione velocissima (massimizzazione dei registri).\n",
    "3. Stima delle Distanze: Al passo $t$, il contatore del nodo $x$ stima quanti nodi sono raggiungibili in $\\le t$ passi (chiamiamo questa stima $N_t$). Al passo precedente ($t-1$), sapevi quanti erano raggiungibili in $\\le t-1$ passi ($N_{t-1}$). La differenza $N_t - N_{t-1}$ ti dice approssimativamente quanti nodi sono esattamente a distanza $t$.\n",
    "4. Calcolo della Centralità: Sapendo quanti nodi sono a distanza $t$, puoi aggiungere quel numero moltiplicato per $\\frac{1}{t}$ al totale della tua Harmonic Centrality."
   ],
   "id": "e0b9491bfbb58915"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Dettaglio del funzionamento di HyperBall\n",
    "Quando hai pochi nodi (1, 10, 100), l'algoritmo funziona in modo diverso rispetto a quando ne hai milioni. Non guarda tanto l'altezza degli zeri, ma **quanti registri sono rimasti a zero**.\n",
    "\n",
    "Immagina di avere **1024 secchi** (i registri) allineati in un campo sotto la pioggia.\n",
    "Ogni nodo è una goccia di pioggia che cade in un secchio casuale (determinato dai primi 10 bit dell'hash).\n",
    "\n",
    "* **1 Nodo (1 goccia):** Bagna 1 secchio. 1023 secchi sono asciutti (valore 0).\n",
    "* **2 Nodi (2 gocce):** Bagnano probabilmente 2 secchi diversi. 1022 secchi asciutti.\n",
    "* **100 Nodi (100 gocce):** Bagnano circa 90-95 secchi. ~930 secchi sono ancora asciutti.\n",
    "\n",
    "**La matematica della Media Armonica ():**\n",
    "La formula che usi (`sum(2**-M)`) è sensibilissima ai valori bassi.\n",
    "\n",
    "* Se un registro è vuoto (valore 0), contribuisce alla somma con .\n",
    "* Se un registro ha un valore alto (es. 10), contribuisce pochissimo ().\n",
    "\n",
    "Se hai 1 nodo \"fortunato\" che finisce nel registro #5 con valore 10, ma gli altri 1023 registri sono vuoti (valore 0), la somma sarà:\n",
    "\n",
    "\n",
    "\n",
    "*(Nota: senza una correzione specifica chiamata \"Linear Counting\", l'HLL puro sovrastima un po' i numeri piccolissimi, ma l'ordine di grandezza rimane contenuto grazie alla massa di registri a zero).*\n",
    "\n",
    "Quindi: **Finché ci sono tanti registri a zero, la stima rimane bassa**, indipendentemente da quanto è \"fortunato\" quel singolo nodo.\n",
    "\n",
    "### 2. La transizione ai Grandi Numeri\n",
    "\n",
    "Man mano che i nodi aumentano, i secchi si riempiono tutti. Non ci sono più registri a zero.\n",
    "A questo punto, l'algoritmo smette di basarsi sui \"vuoti\" e inizia a basarsi sulla **rarità**.\n",
    "\n",
    "* Con 10.000 nodi, è probabile che in ogni secchio sia caduta almeno una goccia.\n",
    "* Ora guardiamo **dentro** ogni secchio: qual è la goccia \"più rara\" (più leading zeros) che è caduta qui?\n",
    "\n",
    "È qui che entra in gioco la tua intuizione: su 1024 registri, la media dei valori massimi salirà statisticamente in modo molto preciso all'aumentare dei nodi unici.\n",
    "\n",
    "### 3. Perché la Media Armonica?\n",
    "\n",
    "L'uso della media armonica (invece di quella aritmetica) serve proprio a **proteggersi dalla fortuna**.\n",
    "\n",
    "* **Media Aritmetica:** Se su 1024 studenti, 1023 hanno 0 euro e uno ha 1 milione di euro, la media aritmetica dice che sono tutti ricchi (~1000€ a testa). Sbagliato.\n",
    "* **Media Armonica:** È pesantemente influenzata dai valori bassi. Nello stesso esempio, la media armonica direbbe che la ricchezza è vicina a 0.\n",
    "\n",
    "Nell'HyperBall:\n",
    "Se un nodo ha un hash rarissimo (30 zeri) ma è l'unico nodo che ho incontrato, gli altri 1023 registri a zero \"tirano giù\" la stima con una forza enorme, impedendo che quel singolo evento fortunato faccia schizzare la cardinalità stimata a miliardi.\n",
    "\n",
    "### 4. Precisione e Limiti\n",
    "\n",
    "Non è *perfetto*. È una stima probabilistica.\n",
    "Con  registri (), l'errore standard è circa:\n",
    "\n",
    "Significa che se il numero reale è 100, l'algoritmo potrebbe dirti 97 o 103. Se è 1.000.000, potrebbe dirti 1.030.000.\n",
    "Per calcolare la centralità in un grafo, questo errore è assolutamente accettabile perché ti interessa l'ordine di grandezza e la classifica relativa dei nodi, non il numero atomico esatto.\n"
   ],
   "id": "22bee4a91c53742"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Versione 1: calcolo su CPU usando dizionari e HyperLogLog",
   "id": "ab5f67440a261770"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T22:18:50.560522800Z",
     "start_time": "2025-12-24T22:18:50.541163800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from datasketch import HyperLogLog\n",
    "import copy\n",
    "import time\n",
    "\n",
    "def harmonic_v1_CPU(G, p=10):\n",
    "    \"\"\"\n",
    "    Calcola la Harmonic Centrality approssimata usando HyperBall.\n",
    "\n",
    "    Args:\n",
    "        G: Oggetto NetworkX DiGraph (350k nodi).\n",
    "        p: Precisione dei registri (p=10 -> 2^10 registri = errore ~3%).\n",
    "           Valori più bassi usano meno RAM ma sono meno precisi.\n",
    "    \"\"\"\n",
    "\n",
    "    # =========================================================================\n",
    "    # FASE 1: PREPARAZIONE E INIZIALIZZAZIONE\n",
    "    # =========================================================================\n",
    "    # Per calcolare la centralità \"in entrata\" (quanto sono importante),\n",
    "    # dobbiamo contare chi può raggiungere ME. HyperBall propaga \"in avanti\",\n",
    "    # quindi lavoriamo sul grafo trasposto (archi invertiti).\n",
    "    print(f\"--- FASE 1: Inversione grafo e Inizializzazione HLL (p={p}) ---\")\n",
    "    G_rev = G.reverse()\n",
    "    nodes = list(G_rev.nodes())\n",
    "\n",
    "    # =========================================================================\n",
    "    # FASE 2: COSTRUZIONE DELLA MATRICE DI CONTATORI\n",
    "    # =========================================================================\n",
    "\n",
    "    # Dizionario per i contatori attuali: {nodo: HyperLogLog}\n",
    "    # Inizialmente ogni nodo conosce solo se stesso (distanza 0).\n",
    "    counters = {}\n",
    "    for node in nodes:\n",
    "        hll = HyperLogLog(p=p)\n",
    "        # HLL richiede input in bytes. Convertiamo l'ID del nodo.\n",
    "        node_id_encoded = str(node).encode('utf-8')\n",
    "        # Aggiungo il nodo stesso al contatore (inizialmente l'insieme dei nodi raggiungibili contiene solo se stesso\n",
    "        hll.update(node_id_encoded)\n",
    "        # Aggiungo il contatore al dizionario che associa ogni nodo ad un contatore HyperLogLog\n",
    "        counters[node] = hll\n",
    "\n",
    "    # Dizionari per memorizzare i risultati\n",
    "    # per ogni nodo in nodes, aggiungi al dizionario la coppia chiave-valore (node:0.0)\n",
    "    harmonic_centrality = {node: 0.0 for node in nodes}\n",
    "\n",
    "    # Memorizziamo la cardinalità al passo precedente (N_{t-1}).\n",
    "    # Al tempo t=0, ogni nodo raggiunge solo se stesso, quindi count = 1.\n",
    "    prev_cardinality = {node: 1.0 for node in nodes}\n",
    "\n",
    "    print(\"Inizializzazione completata.\")\n",
    "\n",
    "    # =========================================================================\n",
    "    # FASE 2: LOOP PRINCIPALE (Espansione della 'Palla') [cite: 771, 778]\n",
    "    # =========================================================================\n",
    "    # Iteriamo per t = 1, 2, ... fino a che le stime non cambiano più (stabilizzazione).\n",
    "    # t rappresenta la distanza (raggiungibili in t passi).\n",
    "    t = 0\n",
    "    changed = True\n",
    "\n",
    "    while changed:\n",
    "        t += 1\n",
    "        changed = False\n",
    "        print(f\"--- Inizio Iterazione t={t} ---\")\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Buffer per i nuovi contatori del passo t\n",
    "        next_counters = {}\n",
    "\n",
    "        # =====================================================================\n",
    "        # FASE 3: UNIONE DEI CONTATORI (Propagazione) [cite: 775, 780]\n",
    "        # =====================================================================\n",
    "        # Logica: I nodi che posso raggiungere in t passi sono l'unione di:\n",
    "        # 1. Quelli che raggiungevo già (me stesso e i vecchi percorsi)\n",
    "        # 2. Quelli che raggiungono i miei vicini al passo t-1.\n",
    "\n",
    "        for node in nodes:\n",
    "            # Copiamo il contatore attuale del nodo (stato t-1)\n",
    "            # NOTA: copy è necessario perché HLL è mutabile\n",
    "            hll_new = copy.copy(counters[node])\n",
    "\n",
    "            # Uniamo con i contatori dei vicini (successori nel grafo trasposto, G_rev.neighbors() = G.successors())\n",
    "            # Questo simula il passaggio di informazioni \"indietro\" nel grafo originale\n",
    "            neighbors = list(G_rev.neighbors(node))\n",
    "\n",
    "            if neighbors:\n",
    "                for neighbor in neighbors:\n",
    "                    # L'operazione di unione HLL è molto veloce (bit-wise OR dei registri)\n",
    "                    hll_new.merge(counters[neighbor])\n",
    "\n",
    "            # Salviamo il nuovo stato\n",
    "            next_counters[node] = hll_new\n",
    "\n",
    "        # =====================================================================\n",
    "        # FASE 4: AGGIORNAMENTO METRICA (Calcolo Harmonic)\n",
    "        # =====================================================================\n",
    "        # Formula: H(x) = sum [ (N_t - N_{t-1}) / t ]\n",
    "        # Dove (N_t - N_{t-1}) è la stima dei nodi trovati ESATTAMENTE a distanza t.\n",
    "\n",
    "        current_change_count = 0\n",
    "\n",
    "        for node in nodes:\n",
    "            old_count = prev_cardinality[node]\n",
    "            new_count = next_counters[node].count()\n",
    "\n",
    "            # Se la stima è aumentata, abbiamo trovato nuovi nodi a distanza t\n",
    "            if new_count > old_count:\n",
    "                delta = new_count - old_count\n",
    "\n",
    "                # Aggiungiamo il contributo alla centralità armonica\n",
    "                harmonic_centrality[node] += delta * (1.0 / t)\n",
    "\n",
    "                # Aggiorniamo la memoria per il prossimo passo\n",
    "                prev_cardinality[node] = new_count\n",
    "\n",
    "                # Segnaliamo che c'è stato un cambiamento nel sistema\n",
    "                changed = True\n",
    "                current_change_count += 1\n",
    "\n",
    "        # =====================================================================\n",
    "        # FASE 5: CHIUSURA ITERAZIONE E CONTROLLO CONVERGENZA [cite: 833]\n",
    "        # =====================================================================\n",
    "        # Scambiamo i buffer: i contatori 'next' diventano quelli attuali per il prossimo t\n",
    "        counters = next_counters\n",
    "\n",
    "        elapsed = time.time() - start_time\n",
    "        print(f\"Fine t={t}. Nodi aggiornati: {current_change_count}. Tempo: {elapsed:.2f}s\")\n",
    "\n",
    "        # Sicurezza per evitare loop infiniti in grafi patologici,\n",
    "        # anche se HLL converge tipicamente entro il diametro effettivo del grafo.\n",
    "        if t > 1000: # Cutoff arbitrario, aumentabile\n",
    "            print(\"Raggiunto limite massimo iterazioni.\")\n",
    "            break\n",
    "\n",
    "    return harmonic_centrality"
   ],
   "id": "cfcf3e32dfe2cbe",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "---",
   "id": "83e4622dca05c618"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Versione 2: calcolo su CPU usando solo matrici NumPy",
   "id": "d8e1ecc1da94bbcb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-26T14:04:23.882499300Z",
     "start_time": "2025-12-26T14:04:23.860076600Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import hashlib\n",
    "import time\n",
    "\n",
    "def harmonic_v2_CPU(G, p=10):\n",
    "    \"\"\"\n",
    "    Versione CPU di HyperBall basata su NumPy.\n",
    "    \"\"\"\n",
    "\n",
    "    # =========================================================================\n",
    "    # FASE 1: SETUP\n",
    "    # =========================================================================\n",
    "    print(f\"--- FASE 1: Setup CPU e Hashing ---\")\n",
    "\n",
    "    G_rev = G.reverse()\n",
    "    nodes = list(G_rev.nodes())\n",
    "    n_nodes = len(nodes)\n",
    "\n",
    "    m = 1 << p\n",
    "    \"\"\"\n",
    "    Numero di registri che compongono ciascun contatore: m = 2^p\n",
    "    \"\"\"\n",
    "\n",
    "    node_to_idx = {node: i for i, node in enumerate(nodes)}\n",
    "    \"\"\"\n",
    "    Mappatura nodo -> indice 0..N-1: dizionario del tipo (k, v) = (node, i), con i risultato dell'enumerazione dell' array di nodi\n",
    "    \"\"\"\n",
    "\n",
    "    edges = np.array([(node_to_idx[u], node_to_idx[v]) for u, v in G_rev.edges()], dtype=np.int32)\n",
    "    \"\"\"\n",
    "    Array di coppie (u_index, v_index), una per ogni edge del tipo (u, v) in G_rev\n",
    "    \"\"\"\n",
    "\n",
    "    M = np.zeros((n_nodes, m), dtype=np.int32)\n",
    "    \"\"\"\n",
    "    Matrice [n_nodes x m] dei contatori;\n",
    "    Dato che un registro deve contenere il numero di leading zeroes di un hash (64 bits), il massimo valore inseribile in ciascun registro sara' < 64 (dato che i primi b bits dell' hash servono a individuare il registro corretto tra gli m), quindi 1 byte (uint8) e' sufficiente (qui usiamo int32 per sicurezza e compatibilità).\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"Calcolo hash iniziali su CPU...\")\n",
    "\n",
    "    # Pre-calcolo hash per ogni nodo per inizializzare M\n",
    "    for i, node in enumerate(nodes):\n",
    "        # Hash del nodo (crea hash con algoritmo md5 e trasforma il risultato in stringa hex, poi converte in intero a partire da base 16 verso base 10)\n",
    "        h = int(hashlib.md5(str(node).encode('utf8')).hexdigest(), 16)\n",
    "\n",
    "        # AND binario tra l' hash h e il numero m-1 = (2^10 - 1) = 1023 = sequenza di zeri seguiti da 10 valori '1'\n",
    "        # il risultato corrisponde agli ultimi 10 bit di h, che selezionano il registro in cui scrivere il numero di leading zeroes\n",
    "        j = h & (m - 1)\n",
    "\n",
    "        # Right shift per rimuovere da h gli ultimi 10 bit estratti in precedenza\n",
    "        w = h >> p\n",
    "\n",
    "        # Conteggio del numero di trailing zeroes della porzione di hash rimanente (+1)\n",
    "        rho = 1\n",
    "        while (w & 1) == 0 and rho < 32: # while l'ultimo bit di w è uno '0':\n",
    "            w >>= 1\n",
    "            rho += 1\n",
    "        M[i, j] = rho\n",
    "\n",
    "    # =========================================================================\n",
    "    # FASE 2: PREPARAZIONE DATI\n",
    "    # =========================================================================\n",
    "    print(f\"--- FASE 2: Preparazione vettori NumPy ---\")\n",
    "\n",
    "    if len(edges) > 0:\n",
    "        sources = edges[:, 1]\n",
    "        \"\"\" Array monodimensionale ottenuto prendendo SOLO (tutta) la colonna 1 di edges \"\"\"\n",
    "        targets = edges[:, 0]\n",
    "        \"\"\" Array monodimensionale ottenuto prendendo SOLO (tutta) la colonna 0 di edges \"\"\"\n",
    "    else:\n",
    "        sources = np.array([], dtype=np.int32)\n",
    "        targets = np.array([], dtype=np.int32)\n",
    "\n",
    "    # Coppia di arrays per memorizzare le cardinalità al passo t-1 e t\n",
    "    # Inizialmente ogni nodo ha cardinalità 1 (se stesso)\n",
    "    prev_cardinality = np.ones(n_nodes, dtype=np.float32)\n",
    "    harmonic_centrality = np.zeros(n_nodes, dtype=np.float32)\n",
    "\n",
    "    alpha_m = 0.7213 / (1 + 1.079 / m)\n",
    "    factor = alpha_m * (m ** 2)\n",
    "\n",
    "    print(\"Dati pronti. Inizio loop CPU.\")\n",
    "\n",
    "    # =========================================================================\n",
    "    # FASE 3: LOOP PRINCIPALE SU CPU\n",
    "    # =========================================================================\n",
    "    t = 0\n",
    "    changed = True\n",
    "\n",
    "    while changed:\n",
    "        t += 1\n",
    "        changed = False\n",
    "\n",
    "        # Time\n",
    "        start_time = time.time()\n",
    "\n",
    "        M_prev = M.copy()\n",
    "\n",
    "        # PROPAGAZIONE IN AVANTI DEI CONTATORI\n",
    "        # se il numero di archi e' > 0, calcola il massimo tra il registro del nodo sorgente e i registri dei nodi target\n",
    "        if len(sources) > 0:\n",
    "            # Prendi i registri dei nodi sorgente\n",
    "            source_registers = M_prev[sources]\n",
    "            # Aggiorna i nodi target con il massimo\n",
    "            # np.maximum.at è l'equivalente NumPy di cp.maximum.at\n",
    "            np.maximum.at(M, targets, source_registers)\n",
    "\n",
    "        # CONVERSIONI DELLA MATRICE DEI CONTATORI\n",
    "        M_float = M.astype(np.float32)\n",
    "        M_bool = M == 0 # nuova matrice booleana che contiene True se il valore corrispondente in M e' 0\n",
    "\n",
    "        # PRIMA STIMA - MEDIA ARMONICA\n",
    "        reg_pow = np.power(2.0, -M_float)\n",
    "        sum_regs = np.sum(reg_pow, axis=1)\n",
    "\n",
    "        # Gestione divisione per zero (se sum_regs è 0, anche se improbabile con inizializzazione corretta)\n",
    "        with np.errstate(divide='ignore'):\n",
    "            estimate_raw = factor / sum_regs\n",
    "\n",
    "        # CORREZIONE DELLA STIMA TRAMITE LINEAR COUNTING\n",
    "        num_zeros = np.sum(M_bool, axis=1) # conta quanti registri sono rimasti a 0 per ciascun nodo\n",
    "        estimate = estimate_raw.copy()\n",
    "        threshold = 2.5 * m\n",
    "        # Maschera booleana che determina quali nodi devono usare la correzione linear counting\n",
    "        mask_lc = (estimate_raw <= threshold) & (num_zeros > 0)\n",
    "\n",
    "        if np.any(mask_lc):\n",
    "            # Formula: m * log(m / V)\n",
    "            # Calcoliamo solo per i nodi nella maschera\n",
    "            V = num_zeros[mask_lc].astype(np.float32)\n",
    "            estimate[mask_lc] = m * np.log(m / V)\n",
    "\n",
    "        # VERIFICA MODIFICHE RISPETTO ALLA STIMA DI CARDINALITA' PRECEDENTE\n",
    "        diff = estimate - prev_cardinality\n",
    "        mask_changed = diff > 0.001\n",
    "\n",
    "        if np.any(mask_changed):\n",
    "            changed = True\n",
    "            harmonic_centrality[mask_changed] += diff[mask_changed] * (1.0 / t)\n",
    "            prev_cardinality[mask_changed] = estimate[mask_changed]\n",
    "\n",
    "        # Time\n",
    "        elapsed = time.time() - start_time\n",
    "\n",
    "        active_nodes = int(np.sum(mask_changed))\n",
    "        print(f\"Fine t={t}. Tempo CPU: {elapsed:.4f}s. Nodi attivi: {active_nodes}\")\n",
    "\n",
    "        if t > 1000:\n",
    "            break\n",
    "\n",
    "    # =========================================================================\n",
    "    # FASE 4: RECUPERO RISULTATI\n",
    "    # =========================================================================\n",
    "    print(\"Calcolo finito. Restituzione dati...\")\n",
    "\n",
    "    final_centrality = harmonic_centrality\n",
    "    result = {nodes[i]: final_centrality[i] for i in range(n_nodes)}\n",
    "    return result\n"
   ],
   "id": "b8b316f1b6774ddf",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "---",
   "id": "2d94106d95d1832"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Versione 3: calcolo su GPU usando matrici CuPy",
   "id": "71fa11b72ed9ffc9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-26T14:04:27.688093800Z",
     "start_time": "2025-12-26T14:04:23.887000400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import cupy as cp  # <--- Il sostituto di NumPy per GPU\n",
    "import numpy as np # Serve ancora per il setup iniziale su CPU\n",
    "import hashlib\n",
    "import time\n",
    "\n",
    "def harmonic_v3_GPU(G, p=10):\n",
    "    \"\"\"\n",
    "    Versione CUDA di HyperBall ottimizzata per CuPy.\n",
    "    \"\"\"\n",
    "\n",
    "    # =========================================================================\n",
    "    # FASE 1: SETUP SU CPU\n",
    "    # =========================================================================\n",
    "    print(f\"--- FASE 1: Setup CPU e Hashing ---\")\n",
    "\n",
    "    G_rev = G.reverse()\n",
    "    nodes = list(G_rev.nodes())\n",
    "    n_nodes = len(nodes)\n",
    "\n",
    "    m = 1 << p\n",
    "    \"\"\"\n",
    "    Numero di registri che compongono ciascun contatore: m = 2^p\n",
    "    \"\"\"\n",
    "\n",
    "    node_to_idx = {node: i for i, node in enumerate(nodes)}\n",
    "    \"\"\"\n",
    "    Mappatura nodo -> indice 0..N-1: dizionario del tipo (k, v) = (node, i), con i risultato dell'enumerazione dell' array di nodi\n",
    "    \"\"\"\n",
    "\n",
    "    edges = np.array([(node_to_idx[u], node_to_idx[v]) for u, v in G_rev.edges()], dtype=np.int32)\n",
    "    \"\"\"\n",
    "    Array di coppie (u_index, v_index), una per ogni edge del tipo (u, v) in G_rev\n",
    "    \"\"\"\n",
    "\n",
    "    M_cpu = np.zeros((n_nodes, m), dtype=np.int32)\n",
    "    \"\"\"\n",
    "    Matrice [n_nodes x m] dei contatori;\n",
    "    Dato che un registro deve contenere il numero di leading zeroes di un hash (64 bits), il massimo valore inseribile in ciascun registro sara' < 64 (dato che i primi b bits dell' hash servono a individuare il registro corretto tra gli m), quindi 1 byte (uint8) e' sufficiente.\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"Calcolo hash iniziali su CPU...\")\n",
    "\n",
    "    # Pre-calcolo hash per ogni nodo per inizializzare M\n",
    "    for i, node in enumerate(nodes):\n",
    "        # Hash del nodo (crea hash con algoritmo md5 e trasforma il risultato in stringa hex, poi converte in intero a partire da base 16 verso base 10)\n",
    "        h = int(hashlib.md5(str(node).encode('utf8')).hexdigest(), 16)\n",
    "\n",
    "        # AND binario tra l' hash h e il numero m-1 = (2^10 - 1) = 1023 = sequenza di zeri seguiti da 10 valori '1'\n",
    "        # il risultato corrisponde agli ultimi 10 bit di h, che selezionano il registro in cui scrivere il numero di leading zeroes\n",
    "        j = h & (m - 1)\n",
    "\n",
    "        # Right shift per rimuovere da h gli ultimi 10 bit estratti in precedenza\n",
    "        w = h >> p\n",
    "\n",
    "        # Conteggio del numero di trailing zeroes della porzione di hash rimanente (+1)\n",
    "        rho = 1\n",
    "        while (w & 1) == 0 and rho < 32: # while l'ultimo bit di w è uno '0':\n",
    "            w >>= 1\n",
    "            rho += 1\n",
    "        M_cpu[i, j] = rho\n",
    "\n",
    "    # =========================================================================\n",
    "    # FASE 2: TRASFERIMENTO SU GPU\n",
    "    # =========================================================================\n",
    "    print(f\"--- FASE 2: Spostamento dati su GPU ---\")\n",
    "\n",
    "    M_gpu = cp.asarray(M_cpu)\n",
    "\n",
    "    if len(edges) > 0:\n",
    "        sources_gpu = cp.asarray(edges[:, 1])\n",
    "        \"\"\" Array monodimensionale ottenuto prendendo SOLO (tutta) la colonna 1 di edges \"\"\"\n",
    "        targets_gpu = cp.asarray(edges[:, 0])\n",
    "        \"\"\" Array monodimensionale ottenuto prendendo SOLO (tutta) la colonna 0 di edges \"\"\"\n",
    "    else:\n",
    "        sources_gpu = cp.array([], dtype=cp.int32)\n",
    "        targets_gpu = cp.array([], dtype=cp.int32)\n",
    "\n",
    "    # Coppia di arrays per memorizzare le cardinalità al passo t-1 e t\n",
    "    # Inizialmente ogni nodo ha cardinalità 1 (se stesso)\n",
    "    prev_cardinality_gpu = cp.ones(n_nodes, dtype=cp.float32)\n",
    "    harmonic_centrality_gpu = cp.zeros(n_nodes, dtype=cp.float32)\n",
    "\n",
    "    alpha_m = 0.7213 / (1 + 1.079 / m)\n",
    "    factor = alpha_m * (m ** 2)\n",
    "\n",
    "    del M_cpu, edges\n",
    "\n",
    "    print(\"Dati in VRAM. Inizio loop GPU.\")\n",
    "\n",
    "    # =========================================================================\n",
    "    # FASE 3: LOOP PRINCIPALE SU GPU\n",
    "    # =========================================================================\n",
    "    t = 0\n",
    "    changed = True\n",
    "\n",
    "    while changed:\n",
    "        t += 1\n",
    "        changed = False\n",
    "\n",
    "        # Time\n",
    "        cp.cuda.Stream.null.synchronize()\n",
    "        start_time = time.time()\n",
    "\n",
    "        M_gpu_prev = M_gpu.copy()\n",
    "\n",
    "        # PROPAGAZIONE IN AVANTI DEI CONTATORI\n",
    "        # se il numero di archi e' > 0, calcola il massimo tra il registro del nodo sorgente e i registri dei nodi target\n",
    "        if len(sources_gpu) > 0:\n",
    "            # Prendi i registri dei nodi sorgente\n",
    "            source_registers = M_gpu_prev[sources_gpu]\n",
    "            # Aggiorna i nodi target con il massimo\n",
    "            cp.maximum.at(M_gpu, targets_gpu, source_registers)\n",
    "\n",
    "        # CONVERSIONI DELLA MATRICE DEI CONTATORI\n",
    "        M_gpu_float = M_gpu.astype(cp.float32)\n",
    "        M_gpu_bool = M_gpu == 0 # nuova matrice booleana che contiene True se il valore corrispondente in M_gpu e' 0\n",
    "\n",
    "        # PRIMA STIMA - MEDIA ARMONICA\n",
    "        reg_pow = cp.power(2.0, -M_gpu_float)\n",
    "        sum_regs = cp.sum(reg_pow, axis=1)\n",
    "        estimate_raw = factor / sum_regs\n",
    "\n",
    "        # CORREZIONE DELLA STIMA TRAMITE LINEAR COUNTING\n",
    "        num_zeros = cp.sum(M_gpu_bool, axis=1) # conta quanti registri sono rimasti a 0 per ciascun nodo (dato che True e' considerato 1)\n",
    "        estimate = estimate_raw.copy()\n",
    "        threshold = 2.5 * m\n",
    "        # Maschera booleana che determina quali nodi devono usare la correzione linear counting. un elemento del vettore e' true solo se entrambe le condizioni sono verificate (AND bitwise)\n",
    "        mask_lc = (estimate_raw <= threshold) & (num_zeros > 0)\n",
    "\n",
    "        if cp.any(mask_lc):\n",
    "            # Formula: m * log(m / V)\n",
    "            # Calcoliamo solo per i nodi nella maschera\n",
    "            V = num_zeros[mask_lc].astype(cp.float32)\n",
    "            estimate[mask_lc] = m * cp.log(m / V)\n",
    "\n",
    "        # VERIFICA MODIFICHE RISPETTO ALLA STIMA DI CARDINALITA' PRECEDENTE\n",
    "        diff = estimate - prev_cardinality_gpu\n",
    "        mask_changed = diff > 0.001\n",
    "\n",
    "        if cp.any(mask_changed):\n",
    "            changed = True\n",
    "            harmonic_centrality_gpu[mask_changed] += diff[mask_changed] * (1.0 / t)\n",
    "            prev_cardinality_gpu[mask_changed] = estimate[mask_changed]\n",
    "\n",
    "        # Time\n",
    "        cp.cuda.Stream.null.synchronize()\n",
    "        elapsed = time.time() - start_time\n",
    "\n",
    "        active_nodes = int(cp.sum(mask_changed))\n",
    "        print(f\"Fine t={t}. Tempo GPU: {elapsed:.4f}s. Nodi attivi: {active_nodes}\")\n",
    "\n",
    "        if t > 1000:\n",
    "            break\n",
    "\n",
    "    # =========================================================================\n",
    "    # FASE 4: RECUPERO RISULTATI\n",
    "    # =========================================================================\n",
    "    print(\"Calcolo finito. Recupero dati dalla GPU...\")\n",
    "\n",
    "    final_centrality = harmonic_centrality_gpu.get()\n",
    "    result = {nodes[i]: final_centrality[i] for i in range(n_nodes)}\n",
    "    return result\n"
   ],
   "id": "1532c7470229f567",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "---",
   "id": "cdbb4ab94d6cfe2b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Calcolo Harmonic Centrality con metodo HyperBall",
   "id": "26b8ca01fcc05e02"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import csv\n",
    "\n",
    "def save_centrality_to_csv(centrality_dict, filename=\"harmonic_centrality_results.csv\"):\n",
    "    \"\"\"\n",
    "    Salva il dizionario delle centralita' in un file CSV, ordinato per importanza decrescente.\n",
    "\n",
    "    Args:\n",
    "        centrality_dict (dict): Dizionario {nodo: score}\n",
    "        filename (str): Nome del file di output\n",
    "    \"\"\"\n",
    "    print(f\"Avvio salvataggio su file: {filename}...\")\n",
    "\n",
    "    # 1. Ordinamento dei dati\n",
    "    # Trasforma il dizionario in una lista di tuple (nodo, score) ordinata per score decrescente\n",
    "    # key=lambda x: x[1] indica di ordinare in base al valore (lo score)\n",
    "    sorted_data = sorted(centrality_dict.items(), key=lambda item: item[1], reverse=True)\n",
    "\n",
    "    # 2. Scrittura su file\n",
    "    try:\n",
    "        # newline='' è importante su Windows per evitare righe vuote extra\n",
    "        with open(filename, mode='w', newline='', encoding='utf-8') as csvfile:\n",
    "            writer = csv.writer(csvfile)\n",
    "\n",
    "            # Scrittura dell'intestazione (Header)\n",
    "            writer.writerow(['ASIN', 'Harmonic_Centrality'])\n",
    "\n",
    "            # Scrittura di tutte le righe in un colpo solo\n",
    "            writer.writerows(sorted_data)\n",
    "\n",
    "        print(f\"Salvataggio completato con successo! ({len(sorted_data)} righe scritte)\")\n",
    "        print(f\"Il nodo più centrale è '{sorted_data[0][0]}' con score {sorted_data[0][1]:.4f}\")\n",
    "\n",
    "    except IOError as e:\n",
    "        print(f\"Errore durante il salvataggio del file: {e}\")"
   ],
   "id": "254f5c58c51c089d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-26T14:06:45.497063Z",
     "start_time": "2025-12-26T14:06:45.441430400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # centrality_scores = harmonic_v1_CPU(G, p=10)\n",
    "    # centrality_scores = harmonic_v2_CPU(G, p=10)\n",
    "    centrality_scores = harmonic_v3_GPU(G, p=10)\n",
    "\n",
    "    # Stampa top 5\n",
    "    top_5 = sorted(centrality_scores.items(), key=lambda x: x[1], reverse=True)[:5]\n",
    "    print(\"Top 5 nodi per Harmonic Centrality:\", top_5)\n",
    "    save_centrality_to_csv(centrality_scores, \"../data/processed/harmonic_scores_v1.csv\")"
   ],
   "id": "e56b966b372d5ea7",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'G' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[5]\u001B[39m\u001B[32m, line 4\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[34m__name__\u001B[39m == \u001B[33m\"\u001B[39m\u001B[33m__main__\u001B[39m\u001B[33m\"\u001B[39m:\n\u001B[32m      2\u001B[39m     \u001B[38;5;66;03m# centrality_scores = harmonic_v1_CPU(G, p=10)\u001B[39;00m\n\u001B[32m      3\u001B[39m     \u001B[38;5;66;03m# centrality_scores = harmonic_v2_CPU(G, p=10)\u001B[39;00m\n\u001B[32m----> \u001B[39m\u001B[32m4\u001B[39m     centrality_scores = harmonic_v3_GPU(\u001B[43mG\u001B[49m, p=\u001B[32m10\u001B[39m)\n\u001B[32m      6\u001B[39m     \u001B[38;5;66;03m# Stampa top 5\u001B[39;00m\n\u001B[32m      7\u001B[39m     top_5 = \u001B[38;5;28msorted\u001B[39m(centrality_scores.items(), key=\u001B[38;5;28;01mlambda\u001B[39;00m x: x[\u001B[32m1\u001B[39m], reverse=\u001B[38;5;28;01mTrue\u001B[39;00m)[:\u001B[32m5\u001B[39m]\n",
      "\u001B[31mNameError\u001B[39m: name 'G' is not defined"
     ]
    }
   ],
   "execution_count": 5
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
