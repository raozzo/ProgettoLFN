{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Approximated Harmonic Centrality",
   "id": "1990977e9da64fa6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Libraries import & graph retrieval",
   "id": "c326893dd7adb579"
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-27T10:54:48.006796700Z",
     "start_time": "2025-12-27T10:54:46.631960700Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pickle               # to read the Amazon DiGraph\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import gc\n",
    "\n",
    "graph_path = \"../data/processed/amazon_graph.pickle\"\n",
    "with open(graph_path, \"rb\") as f:\n",
    "    G = pickle.load(f)"
   ],
   "id": "b29d97a71f269d3b",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "## Hyperball Algorithm\n",
    "\n",
    "HyperBall è l'algoritmo che usa i contatori HLL per calcolare la centralità su tutto il grafo in modo efficiente. L'idea geniale è che non serve fare una visita (BFS) per ogni nodo. Si possono \"muovere\" i contatori.\n",
    "\n",
    "Il Funzionamento Passo-Passo:\n",
    "1. Inizializzazione ($t=0$): Ogni nodo ha un contatore HLL che contiene solo se stesso. Quindi ogni nodo sa di poter raggiungere 1 persona (se stesso) a distanza 0.\n",
    "2. Iterazione ($t=1, 2, \\dots$): Immagina che ogni nodo dica ai suoi vicini: \"Ehi, questi sono tutti i nodi che io so raggiungere\". In termini tecnici: il contatore HLL di un nodo $x$ viene aggiornato facendone l'unione con i contatori HLL dei suoi vicini. Grazie alla matematica degli HLL, l'unione è un'operazione velocissima (massimizzazione dei registri).\n",
    "3. Stima delle Distanze: Al passo $t$, il contatore del nodo $x$ stima quanti nodi sono raggiungibili in $\\le t$ passi (chiamiamo questa stima $N_t$). Al passo precedente ($t-1$), sapevi quanti erano raggiungibili in $\\le t-1$ passi ($N_{t-1}$). La differenza $N_t - N_{t-1}$ ti dice approssimativamente quanti nodi sono esattamente a distanza $t$.\n",
    "4. Calcolo della Centralità: Sapendo quanti nodi sono a distanza $t$, puoi aggiungere quel numero moltiplicato per $\\frac{1}{t}$ al totale della tua Harmonic Centrality."
   ],
   "id": "e0b9491bfbb58915"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Dettaglio del funzionamento di HyperBall\n",
    "Quando hai pochi nodi (1, 10, 100), l'algoritmo funziona in modo diverso rispetto a quando ne hai milioni. Non guarda tanto l'altezza degli zeri, ma **quanti registri sono rimasti a zero**.\n",
    "\n",
    "Immagina di avere **1024 secchi** (i registri) allineati in un campo sotto la pioggia.\n",
    "Ogni nodo è una goccia di pioggia che cade in un secchio casuale (determinato dai primi 10 bit dell'hash).\n",
    "\n",
    "* **1 Nodo (1 goccia):** Bagna 1 secchio. 1023 secchi sono asciutti (valore 0).\n",
    "* **2 Nodi (2 gocce):** Bagnano probabilmente 2 secchi diversi. 1022 secchi asciutti.\n",
    "* **100 Nodi (100 gocce):** Bagnano circa 90-95 secchi. ~930 secchi sono ancora asciutti.\n",
    "\n",
    "**La matematica della Media Armonica ():**\n",
    "La formula che usi (`sum(2**-M)`) è sensibilissima ai valori bassi.\n",
    "\n",
    "* Se un registro è vuoto (valore 0), contribuisce alla somma con .\n",
    "* Se un registro ha un valore alto (es. 10), contribuisce pochissimo ().\n",
    "\n",
    "Se hai 1 nodo \"fortunato\" che finisce nel registro #5 con valore 10, ma gli altri 1023 registri sono vuoti (valore 0), la somma sarà:\n",
    "\n",
    "\n",
    "\n",
    "*(Nota: senza una correzione specifica chiamata \"Linear Counting\", l'HLL puro sovrastima un po' i numeri piccolissimi, ma l'ordine di grandezza rimane contenuto grazie alla massa di registri a zero).*\n",
    "\n",
    "Quindi: **Finché ci sono tanti registri a zero, la stima rimane bassa**, indipendentemente da quanto è \"fortunato\" quel singolo nodo.\n",
    "\n",
    "### 2. La transizione ai Grandi Numeri\n",
    "\n",
    "Man mano che i nodi aumentano, i secchi si riempiono tutti. Non ci sono più registri a zero.\n",
    "A questo punto, l'algoritmo smette di basarsi sui \"vuoti\" e inizia a basarsi sulla **rarità**.\n",
    "\n",
    "* Con 10.000 nodi, è probabile che in ogni secchio sia caduta almeno una goccia.\n",
    "* Ora guardiamo **dentro** ogni secchio: qual è la goccia \"più rara\" (più leading zeros) che è caduta qui?\n",
    "\n",
    "È qui che entra in gioco la tua intuizione: su 1024 registri, la media dei valori massimi salirà statisticamente in modo molto preciso all'aumentare dei nodi unici.\n",
    "\n",
    "### 3. Perché la Media Armonica?\n",
    "\n",
    "L'uso della media armonica (invece di quella aritmetica) serve proprio a **proteggersi dalla fortuna**.\n",
    "\n",
    "* **Media Aritmetica:** Se su 1024 studenti, 1023 hanno 0 euro e uno ha 1 milione di euro, la media aritmetica dice che sono tutti ricchi (~1000€ a testa). Sbagliato.\n",
    "* **Media Armonica:** È pesantemente influenzata dai valori bassi. Nello stesso esempio, la media armonica direbbe che la ricchezza è vicina a 0.\n",
    "\n",
    "Nell'HyperBall:\n",
    "Se un nodo ha un hash rarissimo (30 zeri) ma è l'unico nodo che ho incontrato, gli altri 1023 registri a zero \"tirano giù\" la stima con una forza enorme, impedendo che quel singolo evento fortunato faccia schizzare la cardinalità stimata a miliardi.\n",
    "\n",
    "### 4. Precisione e Limiti\n",
    "\n",
    "Non è *perfetto*. È una stima probabilistica.\n",
    "Con  registri (), l'errore standard è circa:\n",
    "\n",
    "Significa che se il numero reale è 100, l'algoritmo potrebbe dirti 97 o 103. Se è 1.000.000, potrebbe dirti 1.030.000.\n",
    "Per calcolare la centralità in un grafo, questo errore è assolutamente accettabile perché ti interessa l'ordine di grandezza e la classifica relativa dei nodi, non il numero atomico esatto.\n"
   ],
   "id": "22bee4a91c53742"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Versione 1: calcolo su CPU usando dizionari e HyperLogLog",
   "id": "ab5f67440a261770"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-27T10:54:48.542689900Z",
     "start_time": "2025-12-27T10:54:48.006796700Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from datasketch import HyperLogLog\n",
    "import copy\n",
    "\n",
    "def harmonic_v1_CPU(G, p=10):\n",
    "    # =========================================================================\n",
    "    # FASE 1: PREPARAZIONE E INIZIALIZZAZIONE\n",
    "    # =========================================================================\n",
    "    # Per calcolare la centralità \"in entrata\" (quanto sono importante),\n",
    "    # dobbiamo contare chi può raggiungere ME. HyperBall propaga \"in avanti\",\n",
    "    # quindi lavoriamo sul grafo trasposto (archi invertiti).\n",
    "    print(f\"--- FASE 1: Inversione grafo e Inizializzazione HLL (p={p}) ---\")\n",
    "    G_rev = G.reverse()\n",
    "    nodes = list(G_rev.nodes())\n",
    "\n",
    "    # =========================================================================\n",
    "    # FASE 2: COSTRUZIONE DELLA MATRICE DI CONTATORI\n",
    "    # =========================================================================\n",
    "\n",
    "    # Dizionario per i contatori attuali: {nodo: HyperLogLog}\n",
    "    # Inizialmente ogni nodo conosce solo se stesso (distanza 0).\n",
    "    counters = {}\n",
    "    for node in nodes:\n",
    "        hll = HyperLogLog(p=p)\n",
    "        # HLL richiede input in bytes. Convertiamo l'ID del nodo.\n",
    "        node_id_encoded = str(node).encode('utf-8')\n",
    "        # Aggiungo il nodo stesso al contatore (inizialmente l'insieme dei nodi raggiungibili contiene solo se stesso\n",
    "        hll.update(node_id_encoded)\n",
    "        # Aggiungo il contatore al dizionario che associa ogni nodo ad un contatore HyperLogLog\n",
    "        counters[node] = hll\n",
    "\n",
    "    # Dizionari per memorizzare i risultati\n",
    "    # per ogni nodo in nodes, aggiungi al dizionario la coppia chiave-valore (node:0.0)\n",
    "    harmonic_centrality = {node: 0.0 for node in nodes}\n",
    "\n",
    "    # Memorizziamo la cardinalità al passo precedente (N_{t-1}).\n",
    "    # Al tempo t=0, ogni nodo raggiunge solo se stesso, quindi count = 1.\n",
    "    prev_cardinality = {node: 1.0 for node in nodes}\n",
    "\n",
    "    print(\"Inizializzazione completata.\")\n",
    "\n",
    "    # =========================================================================\n",
    "    # FASE 2: LOOP PRINCIPALE (Espansione della 'Palla') [cite: 771, 778]\n",
    "    # =========================================================================\n",
    "    # Iteriamo per t = 1, 2, ... fino a che le stime non cambiano più (stabilizzazione).\n",
    "    # t rappresenta la distanza (raggiungibili in t passi).\n",
    "    t = 0\n",
    "    changed = True\n",
    "\n",
    "    while changed:\n",
    "        t += 1\n",
    "        changed = False\n",
    "        print(f\"--- Inizio Iterazione t={t} ---\")\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Buffer per i nuovi contatori del passo t\n",
    "        next_counters = {}\n",
    "\n",
    "        # =====================================================================\n",
    "        # FASE 3: UNIONE DEI CONTATORI (Propagazione) [cite: 775, 780]\n",
    "        # =====================================================================\n",
    "        # Logica: I nodi che posso raggiungere in t passi sono l'unione di:\n",
    "        # 1. Quelli che raggiungevo già (me stesso e i vecchi percorsi)\n",
    "        # 2. Quelli che raggiungono i miei vicini al passo t-1.\n",
    "\n",
    "        for node in nodes:\n",
    "            # Copiamo il contatore attuale del nodo (stato t-1)\n",
    "            # NOTA: copy è necessario perché HLL è mutabile\n",
    "            hll_new = copy.copy(counters[node])\n",
    "\n",
    "            # Uniamo con i contatori dei vicini (successori nel grafo trasposto, G_rev.neighbors() = G.successors())\n",
    "            # Questo simula il passaggio di informazioni \"indietro\" nel grafo originale\n",
    "            neighbors = list(G_rev.neighbors(node))\n",
    "\n",
    "            if neighbors:\n",
    "                for neighbor in neighbors:\n",
    "                    # L'operazione di unione HLL è molto veloce (bit-wise OR dei registri)\n",
    "                    hll_new.merge(counters[neighbor])\n",
    "\n",
    "            # Salviamo il nuovo stato\n",
    "            next_counters[node] = hll_new\n",
    "\n",
    "        # =====================================================================\n",
    "        # FASE 4: AGGIORNAMENTO METRICA (Calcolo Harmonic)\n",
    "        # =====================================================================\n",
    "        # Formula: H(x) = sum [ (N_t - N_{t-1}) / t ]\n",
    "        # Dove (N_t - N_{t-1}) è la stima dei nodi trovati ESATTAMENTE a distanza t.\n",
    "\n",
    "        current_change_count = 0\n",
    "\n",
    "        for node in nodes:\n",
    "            old_count = prev_cardinality[node]\n",
    "            new_count = next_counters[node].count()\n",
    "\n",
    "            # Se la stima è aumentata, abbiamo trovato nuovi nodi a distanza t\n",
    "            if new_count > old_count:\n",
    "                delta = new_count - old_count\n",
    "\n",
    "                # Aggiungiamo il contributo alla centralità armonica\n",
    "                harmonic_centrality[node] += delta * (1.0 / t)\n",
    "\n",
    "                # Aggiorniamo la memoria per il prossimo passo\n",
    "                prev_cardinality[node] = new_count\n",
    "\n",
    "                # Segnaliamo che c'è stato un cambiamento nel sistema\n",
    "                changed = True\n",
    "                current_change_count += 1\n",
    "\n",
    "        # =====================================================================\n",
    "        # FASE 5: CHIUSURA ITERAZIONE E CONTROLLO CONVERGENZA [cite: 833]\n",
    "        # =====================================================================\n",
    "        # Scambiamo i buffer: i contatori 'next' diventano quelli attuali per il prossimo t\n",
    "        counters = next_counters\n",
    "\n",
    "        elapsed = time.time() - start_time\n",
    "        print(f\"Fine t={t}. Nodi aggiornati: {current_change_count}. Tempo: {elapsed:.2f}s\")\n",
    "\n",
    "        # Sicurezza per evitare loop infiniti in grafi patologici,\n",
    "        # anche se HLL converge tipicamente entro il diametro effettivo del grafo.\n",
    "        if t > 1000: # Cutoff arbitrario, aumentabile\n",
    "            print(\"Raggiunto limite massimo iterazioni.\")\n",
    "            break\n",
    "\n",
    "    return pd.DataFrame(data = list(harmonic_centrality.items()),\n",
    "                        columns=['ASIN', 'HarmonicCentrality'])"
   ],
   "id": "cfcf3e32dfe2cbe",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "---",
   "id": "83e4622dca05c618"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Versione 2: CPU (matrici numPy e pre-allocazione buffer)",
   "id": "d8e1ecc1da94bbcb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-27T10:54:48.802177300Z",
     "start_time": "2025-12-27T10:54:48.787268Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import hashlib\n",
    "\n",
    "def harmonic_v2_CPU(G, p=10):\n",
    "\n",
    "    # DEFINIZIONE STRUTTURE BASE PER TRATTARE IL GRAFO NETWORKX\n",
    "    print(f\"--- FASE 1: Setup CPU e Hashing ---\")\n",
    "\n",
    "    G_rev = G.reverse()\n",
    "    nodes = list(G_rev.nodes())\n",
    "    n_nodes = len(nodes)\n",
    "\n",
    "    m = 1 << p\n",
    "    \"\"\"\n",
    "    Numero di registri che compongono ciascun contatore: m = 2^p\n",
    "    \"\"\"\n",
    "\n",
    "    node_to_idx = {node: i for i, node in enumerate(nodes)}\n",
    "    \"\"\"\n",
    "    Mappatura nodo -> indice 0..N-1: dizionario del tipo (k, v) = (node, i), con i risultato dell'enumerazione dell' array di nodi\n",
    "    \"\"\"\n",
    "\n",
    "    edges = np.array([(node_to_idx[u], node_to_idx[v]) for u, v in G_rev.edges()], dtype=np.int32)\n",
    "    \"\"\"\n",
    "    Array di coppie (u_index, v_index), una per ogni edge del tipo (u, v) in G_rev\n",
    "    \"\"\"\n",
    "\n",
    "    # DEFINIZIONE MATRICE DEI CONTATORI\n",
    "    M_A = np.zeros((n_nodes, m), dtype=np.uint8)\n",
    "    \"\"\"\n",
    "    Matrice [n_nodes x m] dei contatori;\n",
    "    Dato che un registro deve contenere il numero di leading zeroes di un hash (64 bits), il massimo valore inseribile in ciascun registro sara' < 64 (dato che i primi b bits dell' hash servono a individuare il registro corretto tra gli m), quindi 1 byte (uint8) e' sufficiente.\n",
    "    \"\"\"\n",
    "\n",
    "    # CALCOLO DEGLI HASH\n",
    "    print(\"Calcolo hash iniziali su CPU...\")\n",
    "    for i, node in enumerate(nodes):\n",
    "        # Hash del nodo (crea hash con algoritmo md5 e trasforma il risultato in stringa hex, poi converte in intero a partire da base 16 verso base 10)\n",
    "        h = int(hashlib.md5(str(node).encode('utf8')).hexdigest(), 16)\n",
    "\n",
    "        # AND binario tra l' hash h e il numero m-1 = (2^10 - 1) = 1023 = sequenza di zeri seguiti da 10 valori '1'\n",
    "        # il risultato corrisponde agli ultimi 10 bit di h, che selezionano il registro in cui scrivere il numero di leading zeroes\n",
    "        j = h & (m - 1)\n",
    "\n",
    "        # Right shift per rimuovere da h gli ultimi 10 bit estratti in precedenza\n",
    "        w = h >> p\n",
    "\n",
    "        # Conteggio del numero di trailing zeroes della porzione di hash rimanente (+1)\n",
    "        rho = 1\n",
    "        while (w & 1) == 0 and rho < 32: # while l'ultimo bit di w è uno '0':\n",
    "            w >>= 1\n",
    "            rho += 1\n",
    "        M_A[i, j] = rho\n",
    "\n",
    "    # STRUTTURE DATI HYPERBALL E PREALLOCAZIONE\n",
    "    M_B = M_A.copy()\n",
    "    M_float = np.empty((n_nodes, m), dtype=np.float32)\n",
    "    sources = edges[:, 1] # Array monodimensionale ottenuto prendendo SOLO (tutta) la colonna 1 di edges\n",
    "    targets = edges[:, 0] # Array monodimensionale ottenuto prendendo SOLO (tutta) la colonna 0 di edges\n",
    "\n",
    "    # Coppia di arrays per memorizzare le cardinalità al passo t-1 e t\n",
    "    # Inizialmente ogni nodo ha cardinalità 1 (se stesso)\n",
    "    prev_cardinality = np.ones(n_nodes, dtype=np.float32)\n",
    "    harmonic_centrality = np.zeros(n_nodes, dtype=np.float32)\n",
    "\n",
    "    alpha_m = 0.7213 / (1 + 1.079 / m)\n",
    "    factor = alpha_m * (m ** 2)\n",
    "\n",
    "    # PULIZIA RAM\n",
    "    del G_rev, edges\n",
    "    gc.collect()\n",
    "\n",
    "    print(\"Dati pronti. Inizio loop CPU.\")\n",
    "\n",
    "\n",
    "    # -------------------------------------------------- #\n",
    "    # LOOP PRINCIPALE HYPERBALL                          #\n",
    "    # -------------------------------------------------- #\n",
    "    t = 0\n",
    "    changed = True\n",
    "\n",
    "    while changed:\n",
    "        # Time\n",
    "        start_time = time.time()\n",
    "\n",
    "        t += 1\n",
    "        changed = False\n",
    "\n",
    "        m_src = M_A if t % 2 == 1 else M_B\n",
    "        m_target = M_B if t % 2 == 1 else M_A\n",
    "\n",
    "        # PROPAGAZIONE IN AVANTI DEI CONTATORI\n",
    "        m_target[:] = m_src[:]\n",
    "        if len(sources) > 0:\n",
    "            np.maximum.at(m_target, targets, m_src[sources])\n",
    "\n",
    "        # Conversione in float sfruttando la memoria già allocata (M_float)\n",
    "        np.copyto(M_float, m_target, casting='safe')\n",
    "\n",
    "        # PRIMA STIMA - MEDIA ARMONICA (in-place)\n",
    "        np.multiply(M_float, -1.0, out=M_float)\n",
    "        np.power(2.0, M_float, out=M_float)\n",
    "        sum_regs = np.sum(M_float, axis=1)\n",
    "        estimate_raw = factor / sum_regs\n",
    "\n",
    "        # CORREZIONE DELLA STIMA TRAMITE LINEAR COUNTING\n",
    "        estimate = estimate_raw.copy()\n",
    "        num_zeros = np.sum(m_target == 0, axis=1) # conta quanti registri sono rimasti a 0 per ciascun nodo\n",
    "        threshold = 2.5 * m\n",
    "        mask_lc = (estimate_raw <= threshold) & (num_zeros > 0) # Maschera booleana che determina quali nodi devono usare la correzione linear counting\n",
    "\n",
    "        if np.any(mask_lc):\n",
    "            # Formula: m * log(m / V)\n",
    "            # Calcoliamo solo per i nodi nella maschera\n",
    "            V = num_zeros[mask_lc].astype(np.float32)\n",
    "            estimate[mask_lc] = m * np.log(m / V)\n",
    "\n",
    "        # VERIFICA MODIFICHE RISPETTO ALLA STIMA DI CARDINALITA' PRECEDENTE\n",
    "        diff = estimate - prev_cardinality\n",
    "        mask_changed = diff > 0.001\n",
    "\n",
    "        if np.any(mask_changed):\n",
    "            changed = True\n",
    "            harmonic_centrality[mask_changed] += diff[mask_changed] * (1.0 / t)\n",
    "            prev_cardinality[mask_changed] = estimate[mask_changed]\n",
    "\n",
    "        # Print finale\n",
    "        elapsed = time.time() - start_time\n",
    "        active_nodes = int(np.sum(mask_changed))\n",
    "        print(f\"Fine t={t}. Tempo CPU: {elapsed:.4f}s. Nodi attivi: {active_nodes}\")\n",
    "\n",
    "        if t > 1000:\n",
    "            break\n",
    "\n",
    "    # =========================================================================\n",
    "    # FASE 4: RECUPERO RISULTATI\n",
    "    # =========================================================================\n",
    "    print(\"Calcolo finito. Restituzione dati...\")\n",
    "    return pd.DataFrame({\n",
    "        'ASIN': nodes,\n",
    "        'HarmonicCentrality': harmonic_centrality\n",
    "    })\n"
   ],
   "id": "b8b316f1b6774ddf",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-27T10:54:48.973569Z",
     "start_time": "2025-12-27T10:54:48.802177300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from numba import njit, prange\n",
    "\n",
    "# [NUOVA] Funzione compilata con Numba per la propagazione ultra-veloce.\n",
    "# L'uso di prange e parallel=True permette di usare tutti i core della CPU.\n",
    "@njit(parallel=True, cache=True)\n",
    "def numba_propagate(sources, targets, m_src, m_target, n_edges, m):\n",
    "    # Inizializziamo il target con i valori correnti del sorgente (in-place)\n",
    "    # Questa parte è seriale ma veloce in Numba\n",
    "    for i in range(m_target.shape[0]):\n",
    "        for j in range(m):\n",
    "            m_target[i, j] = m_src[i, j]\n",
    "\n",
    "    # Propagazione dei massimi attraverso gli archi\n",
    "    # Parallelizziamo sugli archi per massimizzare il throughput\n",
    "    for e in prange(n_edges):\n",
    "        u = sources[e]\n",
    "        v = targets[e]\n",
    "        for j in range(m):\n",
    "            # Operazione di massimo: se il registro del vicino è maggiore, aggiorna\n",
    "            if m_src[u, j] > m_target[v, j]:\n",
    "                m_target[v, j] = m_src[u, j]\n",
    "\n",
    "def harmonic_v2_CPU_optimized(G, p=10):\n",
    "    print(f\"--- FASE 1: Setup CPU e Hashing ---\")\n",
    "    G_rev = G.reverse()\n",
    "    nodes = list(G_rev.nodes())\n",
    "    n_nodes = len(nodes)\n",
    "    m = 1 << p\n",
    "\n",
    "    node_to_idx = {node: i for i, node in enumerate(nodes)}\n",
    "    edges = np.array([(node_to_idx[u], node_to_idx[v]) for u, v in G_rev.edges()], dtype=np.int32)\n",
    "\n",
    "    # Usiamo uint8 (1 byte) per risparmiare RAM\n",
    "    M_A = np.zeros((n_nodes, m), dtype=np.uint8)\n",
    "\n",
    "    print(\"Calcolo hash iniziali...\")\n",
    "    for i, node in enumerate(nodes):\n",
    "        h = int(hashlib.md5(str(node).encode('utf8')).hexdigest(), 16)\n",
    "        j = h & (m - 1)\n",
    "        w = h >> p\n",
    "        rho = 1\n",
    "        while (w & 1) == 0 and rho < 32:\n",
    "            w >>= 1\n",
    "            rho += 1\n",
    "        M_A[i, j] = rho\n",
    "\n",
    "    print(f\"--- FASE 2: Pre-allocazione Buffer ---\")\n",
    "    M_B = M_A.copy()\n",
    "    M_float = np.empty((n_nodes, m), dtype=np.float32)\n",
    "\n",
    "    sources = edges[:, 1]\n",
    "    targets = edges[:, 0]\n",
    "    n_edges = len(sources)\n",
    "\n",
    "    prev_cardinality = np.ones(n_nodes, dtype=np.float32)\n",
    "    harmonic_centrality = np.zeros(n_nodes, dtype=np.float32)\n",
    "    factor = (0.7213 / (1 + 1.079 / m)) * (m ** 2)\n",
    "\n",
    "    del G_rev, edges\n",
    "    gc.collect()\n",
    "\n",
    "    # =========================================================================\n",
    "    # FASE 3: LOOP PRINCIPALE\n",
    "    # =========================================================================\n",
    "    t = 0\n",
    "    changed = True\n",
    "\n",
    "    while changed:\n",
    "        t += 1\n",
    "        changed = False\n",
    "        start_time = time.time()\n",
    "\n",
    "        m_src = M_A if t % 2 == 1 else M_B\n",
    "        m_target = M_B if t % 2 == 1 else M_A\n",
    "\n",
    "        # [MODIFICATA] Sostituito np.maximum.at con la funzione Numba.\n",
    "        # Questo elimina la creazione di matrici temporanee e usa il parallelismo.\n",
    "        if n_edges > 0:\n",
    "            numba_propagate(sources, targets, m_src, m_target, n_edges, m)\n",
    "        else:\n",
    "            m_target[:] = m_src[:]\n",
    "\n",
    "        # Conversione in float in-place\n",
    "        np.copyto(M_float, m_target, casting='safe')\n",
    "\n",
    "        # Calcolo potenze in-place\n",
    "        np.multiply(M_float, -1.0, out=M_float)\n",
    "        np.power(2.0, M_float, out=M_float)\n",
    "\n",
    "        sum_regs = np.sum(M_float, axis=1)\n",
    "        estimate_raw = factor / sum_regs\n",
    "\n",
    "        # Conteggio zeri e correzione Linear Counting\n",
    "        num_zeros = np.sum(m_target == 0, axis=1)\n",
    "        estimate = estimate_raw.copy()\n",
    "\n",
    "        mask_lc = (estimate_raw <= 2.5 * m) & (num_zeros > 0)\n",
    "        if np.any(mask_lc):\n",
    "            V = num_zeros[mask_lc].astype(np.float32)\n",
    "            estimate[mask_lc] = m * np.log(m / V)\n",
    "\n",
    "        # Verifica modifiche\n",
    "        diff = estimate - prev_cardinality\n",
    "        mask_changed = diff > 0.001\n",
    "\n",
    "        if np.any(mask_changed):\n",
    "            changed = True\n",
    "            harmonic_centrality[mask_changed] += diff[mask_changed] * (1.0 / t)\n",
    "            prev_cardinality[mask_changed] = estimate[mask_changed]\n",
    "\n",
    "        elapsed = time.time() - start_time\n",
    "        print(f\"t={t} | Tempo CPU: {elapsed:.2f}s | Nodi attivi: {int(np.sum(mask_changed))}\")\n",
    "\n",
    "        if t > 1000: break\n",
    "\n",
    "    return pd.DataFrame({'ASIN': nodes, 'HarmonicCentrality': harmonic_centrality})"
   ],
   "id": "eb3a30b23fb107e9",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "---",
   "id": "2d94106d95d1832"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Versione 3: GPU (matrici cuPy e pre-allocazione buffer)",
   "id": "b38ceddc26a5ad32"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-27T10:54:48.997512900Z",
     "start_time": "2025-12-27T10:54:48.973569Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import cupy as cp\n",
    "import hashlib\n",
    "import gc\n",
    "\n",
    "def harmonic_v3_GPU(G, p=10):\n",
    "    # =========================================================================\n",
    "    # FASE 1: SETUP SU CPU\n",
    "    # =========================================================================\n",
    "    print(f\"--- FASE 1: Setup CPU e Hashing ---\")\n",
    "\n",
    "    G_rev = G.reverse()\n",
    "    nodes = list(G_rev.nodes())\n",
    "    n_nodes = len(nodes)\n",
    "\n",
    "    m = 1 << p\n",
    "    \"\"\"\n",
    "    Numero di registri che compongono ciascun contatore: m = 2^p\n",
    "    \"\"\"\n",
    "\n",
    "    node_to_idx = {node: i for i, node in enumerate(nodes)}\n",
    "    \"\"\"\n",
    "    Mappatura nodo -> indice 0..N-1: dizionario del tipo (k, v) = (node, i), con i risultato dell'enumerazione dell' array di nodi\n",
    "    \"\"\"\n",
    "\n",
    "    edges = np.array([(node_to_idx[u], node_to_idx[v]) for u, v in G_rev.edges()], dtype=np.int32)\n",
    "    \"\"\"\n",
    "    Array di coppie (u_index, v_index), una per ogni edge del tipo (u, v) in G_rev\n",
    "    \"\"\"\n",
    "\n",
    "    M_cpu = np.zeros((n_nodes, m), dtype=np.int32)\n",
    "    \"\"\"\n",
    "    Matrice [n_nodes x m] dei contatori;\n",
    "    Dato che un registro deve contenere il numero di leading zeroes di un hash (64 bits), il massimo valore inseribile in ciascun registro sara' < 64 (dato che i primi b bits dell' hash servono a individuare il registro corretto tra gli m), quindi 1 byte (uint8) e' sufficiente.\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"Calcolo hash iniziali su CPU...\")\n",
    "\n",
    "    # Pre-calcolo hash per ogni nodo per inizializzare M\n",
    "    for i, node in enumerate(nodes):\n",
    "        # Hash del nodo (crea hash con algoritmo md5 e trasforma il risultato in stringa hex, poi converte in intero a partire da base 16 verso base 10)\n",
    "        h = int(hashlib.md5(str(node).encode('utf8')).hexdigest(), 16)\n",
    "\n",
    "        # AND binario tra l' hash h e il numero m-1 = (2^10 - 1) = 1023 = sequenza di zeri seguiti da 10 valori '1'\n",
    "        # il risultato corrisponde agli ultimi 10 bit di h, che selezionano il registro in cui scrivere il numero di leading zeroes\n",
    "        j = h & (m - 1)\n",
    "\n",
    "        # Right shift per rimuovere da h gli ultimi 10 bit estratti in precedenza\n",
    "        w = h >> p\n",
    "\n",
    "        # Conteggio del numero di trailing zeroes della porzione di hash rimanente (+1)\n",
    "        rho = 1\n",
    "        while (w & 1) == 0 and rho < 32: # while l'ultimo bit di w è uno '0':\n",
    "            w >>= 1\n",
    "            rho += 1\n",
    "        M_cpu[i, j] = rho\n",
    "\n",
    "    # =========================================================================\n",
    "    # FASE 2: TRASFERIMENTO SU GPU\n",
    "    # =========================================================================\n",
    "    print(f\"--- FASE 2: Spostamento dati su GPU, pre-allocazione ---\")\n",
    "    M_A = cp.asarray(M_cpu)         # Matrice corrente\n",
    "    M_B = M_A.copy()                # Matrice per il prossimo passo (Double Buffering)\n",
    "    M_float = cp.empty_like(M_A, dtype=cp.float32) # Buffer per i calcoli float\n",
    "\n",
    "    if len(edges) > 0:\n",
    "        sources_gpu = cp.asarray(edges[:, 1])\n",
    "        \"\"\" Array monodimensionale ottenuto prendendo SOLO (tutta) la colonna 1 di edges \"\"\"\n",
    "        targets_gpu = cp.asarray(edges[:, 0])\n",
    "        \"\"\" Array monodimensionale ottenuto prendendo SOLO (tutta) la colonna 0 di edges \"\"\"\n",
    "    else:\n",
    "        sources_gpu = cp.array([], dtype=cp.int32)\n",
    "        targets_gpu = cp.array([], dtype=cp.int32)\n",
    "\n",
    "    # Coppia di arrays per memorizzare le cardinalità al passo t-1 e t\n",
    "    # Inizialmente ogni nodo ha cardinalità 1 (se stesso)\n",
    "    prev_cardinality_gpu = cp.ones(n_nodes, dtype=cp.float32)\n",
    "    harmonic_centrality_gpu = cp.zeros(n_nodes, dtype=cp.float32)\n",
    "\n",
    "    alpha_m = 0.7213 / (1 + 1.079 / m)\n",
    "    factor = alpha_m * (m ** 2)\n",
    "\n",
    "    del M_cpu, edges\n",
    "    gc.collect()\n",
    "\n",
    "    print(f\"Dati pronti. VRAM inizialmente impegnata: ~{((M_A.nbytes * 3) / 1024**2):.2f} MB\")\n",
    "\n",
    "    # =========================================================================\n",
    "    # FASE 3: LOOP PRINCIPALE SU GPU\n",
    "    # =========================================================================\n",
    "    t = 0\n",
    "    changed = True\n",
    "\n",
    "    while changed:\n",
    "        t += 1\n",
    "        changed = False\n",
    "\n",
    "        # Time\n",
    "        cp.cuda.Stream.null.synchronize()\n",
    "        start_time = time.time()\n",
    "\n",
    "\n",
    "        m_src = M_A if t % 2 == 1 else M_B\n",
    "        m_target = M_B if t % 2 == 1 else M_A\n",
    "\n",
    "\n",
    "        # PROPAGAZIONE IN AVANTI DEI CONTATORI\n",
    "        # se il numero di archi e' > 0, calcola il massimo tra il registro del nodo sorgente e i registri dei nodi target\n",
    "        m_target[:] = m_src[:]\n",
    "        if len(sources_gpu) > 0:\n",
    "            # Aggiorna i nodi target con il massimo\n",
    "            cp.maximum.at(m_target, targets_gpu, m_src[sources_gpu])\n",
    "\n",
    "        # CONVERSIONI DELLA MATRICE DEI CONTATORI\n",
    "        M_float[:] = m_target.astype(cp.float32)\n",
    "\n",
    "        # PRIMA STIMA - MEDIA ARMONICA\n",
    "        cp.multiply(M_float, -1.0, out=M_float)\n",
    "        cp.exp2(M_float, out=M_float)\n",
    "        sum_regs = cp.sum(M_float, axis=1)\n",
    "        estimate_raw = factor / sum_regs\n",
    "\n",
    "        # CORREZIONE DELLA STIMA TRAMITE LINEAR COUNTING\n",
    "        num_zeros = cp.sum(m_target == 0, axis=1) # conta quanti registri sono rimasti a 0 per ciascun nodo (dato che True e' considerato 1)\n",
    "        estimate = estimate_raw.copy()\n",
    "\n",
    "        threshold = 2.5 * m\n",
    "        # Maschera booleana che determina quali nodi devono usare la correzione linear counting. un elemento del vettore e' true solo se entrambe le condizioni sono verificate (AND bitwise)\n",
    "        mask_lc = (estimate_raw <= threshold) & (num_zeros > 0)\n",
    "\n",
    "        if cp.any(mask_lc):\n",
    "            # Formula: m * log(m / V)\n",
    "            # Calcoliamo solo per i nodi nella maschera\n",
    "            V = num_zeros[mask_lc].astype(cp.float32)\n",
    "            estimate[mask_lc] = m * cp.log(m / V)\n",
    "\n",
    "        # VERIFICA MODIFICHE RISPETTO ALLA STIMA DI CARDINALITA' PRECEDENTE\n",
    "        diff = estimate - prev_cardinality_gpu\n",
    "        mask_changed = diff > 0.001\n",
    "\n",
    "        if cp.any(mask_changed):\n",
    "            changed = True\n",
    "            harmonic_centrality_gpu[mask_changed] += diff[mask_changed] * (1.0 / t)\n",
    "            prev_cardinality_gpu[mask_changed] = estimate[mask_changed]\n",
    "\n",
    "        # Time\n",
    "        cp.cuda.Stream.null.synchronize()\n",
    "        elapsed = time.time() - start_time\n",
    "\n",
    "        active_nodes = int(cp.sum(mask_changed))\n",
    "        print(f\"Fine t={t}. Tempo GPU: {elapsed:.4f}s. Nodi attivi: {active_nodes}\")\n",
    "\n",
    "        if t > 1000:\n",
    "            break\n",
    "\n",
    "    # =========================================================================\n",
    "    # FASE 4: RECUPERO RISULTATI\n",
    "    # =========================================================================\n",
    "    print(\"Calcolo terminato. Recupero dati dalla GPU...\")\n",
    "    return pd.DataFrame({\n",
    "        'ASIN': nodes,\n",
    "        'HarmonicCentrality': harmonic_centrality_gpu.get()\n",
    "    })"
   ],
   "id": "dc11bf4de47d436d",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-27T10:54:49.013235200Z",
     "start_time": "2025-12-27T10:54:48.997512900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import cupy as cp\n",
    "import hashlib\n",
    "import gc\n",
    "\n",
    "# Definiamo il Kernel CUDA per la propagazione senza copie di memoria\n",
    "# Questo kernel evita la creazione della matrice temporanea da 4.5GB\n",
    "propagation_kernel = cp.RawKernel(r'''\n",
    "extern \"C\" __global__\n",
    "void propagate_max(const int* sources, const int* targets, const int* src_matrix, int* target_matrix, int n_edges, int m) {\n",
    "    int edge_idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (edge_idx < n_edges) {\n",
    "        int u_idx = sources[edge_idx];\n",
    "        int v_idx = targets[edge_idx];\n",
    "\n",
    "        for (int j = 0; j < m; j++) {\n",
    "            // Esegue l'atomicMax per ogni registro tra il nodo sorgente e il target\n",
    "            atomicMax(&target_matrix[v_idx * m + j], src_matrix[u_idx * m + j]);\n",
    "        }\n",
    "    }\n",
    "}\n",
    "''', 'propagate_max')\n",
    "\n",
    "def harmonic_v3_GPU_optimized(G, p=10):\n",
    "    print(f\"--- FASE 1: Setup CPU e Hashing ---\")\n",
    "    G_rev = G.reverse()\n",
    "    nodes = list(G_rev.nodes())\n",
    "    n_nodes = len(nodes)\n",
    "    m = 1 << p\n",
    "\n",
    "    node_to_idx = {node: i for i, node in enumerate(nodes)}\n",
    "    edges = np.array([(node_to_idx[u], node_to_idx[v]) for u, v in G_rev.edges()], dtype=np.int32)\n",
    "\n",
    "    M_cpu = np.zeros((n_nodes, m), dtype=np.int32)\n",
    "    for i, node in enumerate(nodes):\n",
    "        h = int(hashlib.md5(str(node).encode('utf8')).hexdigest(), 16)\n",
    "        j = h & (m - 1)\n",
    "        w = h >> p\n",
    "        rho = 1\n",
    "        while (w & 1) == 0 and rho < 32:\n",
    "            w >>= 1\n",
    "            rho += 1\n",
    "        M_cpu[i, j] = rho\n",
    "\n",
    "    print(f\"--- FASE 2: Trasferimento e Pre-allocazione ---\")\n",
    "    M_A = cp.asarray(M_cpu)\n",
    "    M_B = M_A.copy()\n",
    "    M_float = cp.empty_like(M_A, dtype=cp.float32)\n",
    "\n",
    "    if len(edges) > 0:\n",
    "        # Nota: usiamo i nomi originali ma la logica del kernel\n",
    "        s_gpu = cp.asarray(edges[:, 1]) # sorgenti degli archi\n",
    "        t_gpu = cp.asarray(edges[:, 0]) # target degli archi\n",
    "        n_edges = len(edges)\n",
    "    else:\n",
    "        n_edges = 0\n",
    "\n",
    "    prev_cardinality_gpu = cp.ones(n_nodes, dtype=cp.float32)\n",
    "    harmonic_centrality_gpu = cp.zeros(n_nodes, dtype=cp.float32)\n",
    "    alpha_m = 0.7213 / (1 + 1.079 / m)\n",
    "    factor = alpha_m * (m ** 2)\n",
    "\n",
    "    del M_cpu, edges, G_rev\n",
    "    gc.collect()\n",
    "\n",
    "    # =========================================================================\n",
    "    # FASE 3: LOOP PRINCIPALE\n",
    "    # =========================================================================\n",
    "    t = 0\n",
    "    changed = True\n",
    "\n",
    "    # Configuriamo i blocchi per il Kernel (128 thread per blocco è uno standard bilanciato)\n",
    "    threads_per_block = 128\n",
    "    grid_size = (n_edges + threads_per_block - 1) // threads_per_block\n",
    "\n",
    "    print(f\"Inizio loop. VRAM statica: ~{((M_A.nbytes * 3) / 1024**2):.2f} MB. No extra allocs.\")\n",
    "\n",
    "    while changed:\n",
    "        t += 1\n",
    "        changed = False\n",
    "        cp.cuda.Stream.null.synchronize()\n",
    "        start_time = time.time()\n",
    "\n",
    "        m_src = M_A if t % 2 == 1 else M_B\n",
    "        m_target = M_B if t % 2 == 1 else M_A\n",
    "\n",
    "        # 1. PROPAGAZIONE (Kernel personalizzato: ZERO copie extra)\n",
    "        m_target[:] = m_src[:]\n",
    "        if n_edges > 0:\n",
    "            propagation_kernel((grid_size,), (threads_per_block,),\n",
    "                               (s_gpu, t_gpu, m_src, m_target, n_edges, m))\n",
    "\n",
    "        # 2. STIMA (Operazioni in-place)\n",
    "        M_float[:] = m_target.astype(cp.float32)\n",
    "        cp.multiply(M_float, -1.0, out=M_float)\n",
    "        cp.exp2(M_float, out=M_float)\n",
    "        sum_regs = cp.sum(M_float, axis=1)\n",
    "        estimate_raw = factor / sum_regs\n",
    "\n",
    "        # 3. CORREZIONE LC\n",
    "        num_zeros = cp.sum(m_target == 0, axis=1)\n",
    "        estimate = estimate_raw.copy()\n",
    "        mask_lc = (estimate_raw <= 2.5 * m) & (num_zeros > 0)\n",
    "        if cp.any(mask_lc):\n",
    "            V = num_zeros[mask_lc].astype(cp.float32)\n",
    "            estimate[mask_lc] = m * cp.log(m / V)\n",
    "\n",
    "        # 4. AGGIORNAMENTO\n",
    "        diff = estimate - prev_cardinality_gpu\n",
    "        mask_changed = diff > 0.001\n",
    "        if cp.any(mask_changed):\n",
    "            changed = True\n",
    "            harmonic_centrality_gpu[mask_changed] += diff[mask_changed] * (1.0 / t)\n",
    "            prev_cardinality_gpu[mask_changed] = estimate[mask_changed]\n",
    "\n",
    "        cp.cuda.Stream.null.synchronize()\n",
    "        elapsed = time.time() - start_time\n",
    "        print(f\"t={t} | Tempo: {elapsed:.4f}s | Nodi Attivi: {int(cp.sum(mask_changed))}\")\n",
    "\n",
    "        if t > 1000: break\n",
    "\n",
    "    # Pulizia\n",
    "    del M_A, M_B, M_float, s_gpu, t_gpu\n",
    "    cp.get_default_memory_pool().free_all_blocks()\n",
    "    gc.collect()\n",
    "\n",
    "    return pd.DataFrame({'ASIN': nodes, 'HarmonicCentrality': harmonic_centrality_gpu.get()})"
   ],
   "id": "ca5d71f8ec9958f7",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "---",
   "id": "ba43361da62b81dd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Calcolo Harmonic Centrality con metodo HyperBall",
   "id": "26b8ca01fcc05e02"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-27T10:55:32.332947800Z",
     "start_time": "2025-12-27T10:54:54.211042600Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Compute Harmonic scores and save them to a csv file\n",
    "    df_harmonic_scores = harmonic_v3_GPU_optimized(G)\n",
    "    df_harmonic_scores.to_csv(\"../data/processed/harm_scores.csv\", index=False)\n",
    "    # cp.get_default_memory_pool().free_all_blocks()\n",
    "\n",
    "    display(df_harmonic_scores.head(5))\n",
    "    print(f\"Computed hc for {len(df_harmonic_scores)} nodes.\")"
   ],
   "id": "e56b966b372d5ea7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- FASE 1: Setup CPU e Hashing ---\n",
      "--- FASE 2: Trasferimento e Pre-allocazione ---\n",
      "Inizio loop. VRAM statica: ~3923.94 MB. No extra allocs.\n",
      "t=1 | Tempo: 0.2792s | Nodi Attivi: 212737\n",
      "t=2 | Tempo: 0.2788s | Nodi Attivi: 177200\n",
      "t=3 | Tempo: 0.2859s | Nodi Attivi: 151752\n",
      "t=4 | Tempo: 0.2515s | Nodi Attivi: 135309\n",
      "t=5 | Tempo: 0.2514s | Nodi Attivi: 123841\n",
      "t=6 | Tempo: 0.2457s | Nodi Attivi: 115746\n",
      "t=7 | Tempo: 0.2423s | Nodi Attivi: 109974\n",
      "t=8 | Tempo: 0.2402s | Nodi Attivi: 105901\n",
      "t=9 | Tempo: 0.2386s | Nodi Attivi: 102913\n",
      "t=10 | Tempo: 0.2309s | Nodi Attivi: 100695\n",
      "t=11 | Tempo: 0.2286s | Nodi Attivi: 98941\n",
      "t=12 | Tempo: 0.2308s | Nodi Attivi: 97592\n",
      "t=13 | Tempo: 0.2323s | Nodi Attivi: 96577\n",
      "t=14 | Tempo: 0.2294s | Nodi Attivi: 95811\n",
      "t=15 | Tempo: 0.2275s | Nodi Attivi: 95206\n",
      "t=16 | Tempo: 0.2277s | Nodi Attivi: 94746\n",
      "t=17 | Tempo: 0.2262s | Nodi Attivi: 94336\n",
      "t=18 | Tempo: 0.2261s | Nodi Attivi: 93999\n",
      "t=19 | Tempo: 0.2288s | Nodi Attivi: 93733\n",
      "t=20 | Tempo: 0.2254s | Nodi Attivi: 93543\n",
      "t=21 | Tempo: 0.2264s | Nodi Attivi: 93395\n",
      "t=22 | Tempo: 0.2263s | Nodi Attivi: 93289\n",
      "t=23 | Tempo: 0.2254s | Nodi Attivi: 93219\n",
      "t=24 | Tempo: 0.2249s | Nodi Attivi: 93184\n",
      "t=25 | Tempo: 0.2250s | Nodi Attivi: 93154\n",
      "t=26 | Tempo: 0.2246s | Nodi Attivi: 93125\n",
      "t=27 | Tempo: 0.2254s | Nodi Attivi: 93105\n",
      "t=28 | Tempo: 0.2250s | Nodi Attivi: 93096\n",
      "t=29 | Tempo: 0.2259s | Nodi Attivi: 93093\n",
      "t=30 | Tempo: 0.2251s | Nodi Attivi: 93090\n",
      "t=31 | Tempo: 0.2252s | Nodi Attivi: 93085\n",
      "t=32 | Tempo: 0.2306s | Nodi Attivi: 93071\n",
      "t=33 | Tempo: 0.2320s | Nodi Attivi: 93038\n",
      "t=34 | Tempo: 0.2329s | Nodi Attivi: 92982\n",
      "t=35 | Tempo: 0.2326s | Nodi Attivi: 92869\n",
      "t=36 | Tempo: 0.2303s | Nodi Attivi: 92643\n",
      "t=37 | Tempo: 0.2260s | Nodi Attivi: 92252\n",
      "t=38 | Tempo: 0.2263s | Nodi Attivi: 91517\n",
      "t=39 | Tempo: 0.2254s | Nodi Attivi: 90497\n",
      "t=40 | Tempo: 0.2251s | Nodi Attivi: 88955\n",
      "t=41 | Tempo: 0.2248s | Nodi Attivi: 86874\n",
      "t=42 | Tempo: 0.2261s | Nodi Attivi: 83946\n",
      "t=43 | Tempo: 0.2255s | Nodi Attivi: 80616\n",
      "t=44 | Tempo: 0.2239s | Nodi Attivi: 76887\n",
      "t=45 | Tempo: 0.2250s | Nodi Attivi: 72858\n",
      "t=46 | Tempo: 0.2245s | Nodi Attivi: 68550\n",
      "t=47 | Tempo: 0.2274s | Nodi Attivi: 64095\n",
      "t=48 | Tempo: 0.2266s | Nodi Attivi: 59607\n",
      "t=49 | Tempo: 0.2269s | Nodi Attivi: 55493\n",
      "t=50 | Tempo: 0.2254s | Nodi Attivi: 51044\n",
      "t=51 | Tempo: 0.2256s | Nodi Attivi: 46705\n",
      "t=52 | Tempo: 0.2255s | Nodi Attivi: 42227\n",
      "t=53 | Tempo: 0.2255s | Nodi Attivi: 37883\n",
      "t=54 | Tempo: 0.2254s | Nodi Attivi: 33856\n",
      "t=55 | Tempo: 0.2254s | Nodi Attivi: 30201\n",
      "t=56 | Tempo: 0.2250s | Nodi Attivi: 26551\n",
      "t=57 | Tempo: 0.2258s | Nodi Attivi: 23156\n",
      "t=58 | Tempo: 0.2255s | Nodi Attivi: 19615\n",
      "t=59 | Tempo: 0.2252s | Nodi Attivi: 16515\n",
      "t=60 | Tempo: 0.2249s | Nodi Attivi: 13979\n",
      "t=61 | Tempo: 0.2251s | Nodi Attivi: 11714\n",
      "t=62 | Tempo: 0.2262s | Nodi Attivi: 9722\n",
      "t=63 | Tempo: 0.2250s | Nodi Attivi: 8053\n",
      "t=64 | Tempo: 0.2253s | Nodi Attivi: 6588\n",
      "t=65 | Tempo: 0.2251s | Nodi Attivi: 5426\n",
      "t=66 | Tempo: 0.2248s | Nodi Attivi: 4242\n",
      "t=67 | Tempo: 0.2247s | Nodi Attivi: 3329\n",
      "t=68 | Tempo: 0.2250s | Nodi Attivi: 2720\n",
      "t=69 | Tempo: 0.2249s | Nodi Attivi: 2229\n",
      "t=70 | Tempo: 0.2247s | Nodi Attivi: 1863\n",
      "t=71 | Tempo: 0.2246s | Nodi Attivi: 1424\n",
      "t=72 | Tempo: 0.2249s | Nodi Attivi: 1071\n",
      "t=73 | Tempo: 0.2249s | Nodi Attivi: 876\n",
      "t=74 | Tempo: 0.2246s | Nodi Attivi: 716\n",
      "t=75 | Tempo: 0.2253s | Nodi Attivi: 592\n",
      "t=76 | Tempo: 0.2263s | Nodi Attivi: 474\n",
      "t=77 | Tempo: 0.2254s | Nodi Attivi: 361\n",
      "t=78 | Tempo: 0.2250s | Nodi Attivi: 277\n",
      "t=79 | Tempo: 0.2250s | Nodi Attivi: 233\n",
      "t=80 | Tempo: 0.2253s | Nodi Attivi: 180\n",
      "t=81 | Tempo: 0.2272s | Nodi Attivi: 134\n",
      "t=82 | Tempo: 0.2250s | Nodi Attivi: 123\n",
      "t=83 | Tempo: 0.2267s | Nodi Attivi: 109\n",
      "t=84 | Tempo: 0.2246s | Nodi Attivi: 84\n",
      "t=85 | Tempo: 0.2257s | Nodi Attivi: 62\n",
      "t=86 | Tempo: 0.2246s | Nodi Attivi: 43\n",
      "t=87 | Tempo: 0.2248s | Nodi Attivi: 31\n",
      "t=88 | Tempo: 0.2274s | Nodi Attivi: 27\n",
      "t=89 | Tempo: 0.2274s | Nodi Attivi: 23\n",
      "t=90 | Tempo: 0.2257s | Nodi Attivi: 19\n",
      "t=91 | Tempo: 0.2255s | Nodi Attivi: 12\n",
      "t=92 | Tempo: 0.2252s | Nodi Attivi: 8\n",
      "t=93 | Tempo: 0.2258s | Nodi Attivi: 5\n",
      "t=94 | Tempo: 0.2247s | Nodi Attivi: 5\n",
      "t=95 | Tempo: 0.2248s | Nodi Attivi: 2\n",
      "t=96 | Tempo: 0.2265s | Nodi Attivi: 2\n",
      "t=97 | Tempo: 0.2264s | Nodi Attivi: 2\n",
      "t=98 | Tempo: 0.2252s | Nodi Attivi: 2\n",
      "t=99 | Tempo: 0.2246s | Nodi Attivi: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "         ASIN  HarmonicCentrality\n",
       "0  0827229534        10890.977539\n",
       "1  0738700797         9056.976562\n",
       "2  0842328327            2.840921\n",
       "3  1577943082            5.111011\n",
       "4  0486220125            0.000000"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ASIN</th>\n",
       "      <th>HarmonicCentrality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0827229534</td>\n",
       "      <td>10890.977539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0738700797</td>\n",
       "      <td>9056.976562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0842328327</td>\n",
       "      <td>2.840921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1577943082</td>\n",
       "      <td>5.111011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0486220125</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed hc for 334843 nodes.\n"
     ]
    }
   ],
   "execution_count": 7
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
