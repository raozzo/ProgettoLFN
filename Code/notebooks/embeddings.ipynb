{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Teoria e Implementazione degli Embeddings: Node2Vec su CPU vs GPU\n",
    "\n",
    "Questo documento esplora il funzionamento teorico degli embeddings su grafo (specificamente Node2Vec) e analizza come l'architettura hardware (CPU vs GPU) influenzi drasticamente l'approccio computazionale, specialmente per grafi di grandi dimensioni (350k nodi).\n",
    "\n",
    "\n",
    "### Il Concetto Teorico: Cos'è un Graph Embedding?\n",
    "L'obiettivo di un embedding è tradurre la struttura complessa e topologica di un grafo in uno spazio vettoriale semplice (spazio Euclideo). Dato un grafo $G = (V, E)$, vogliamo apprendere una funzione $f: V \\rightarrow \\mathbb{R}^d$ (dove $d$ è la dimensione, es. 128) tale che:\n",
    "\n",
    "* Se due nodi $u$ e $v$ sono \"simili\" nel grafo, i loro vettori $z_u$ e $z_v$ devono essere vicini nello spazio vettoriale.\n",
    "\n",
    "La \"vicinanza\" vettoriale è solitamente misurata tramite il prodotto scalare.\n",
    "\n",
    "#### L'Intuizione di Node2Vec\n",
    "Node2Vec si basa su un'analogia linguistica derivata da Word2Vec (NLP):\n",
    "* In un testo, le parole che appaiono nello stesso contesto sono semanticamente simili.\n",
    "* In un grafo, i nodi che appaiono nella stessa \"passeggiata\" (path) sono strutturalmente simili.\n",
    "\n",
    "L'algoritmo si divide in due fasi principali:\n",
    "1. Campionamento (Random Walks): Generazione di sequenze di nodi simulate attraversando il grafo.\n",
    "2. Ottimizzazione (Skip-Gram): Addestramento di una rete neurale per predire i nodi vicini dato un nodo di input.\n",
    "\n",
    "### Fase 1: Random Walks (Il Collo di Bottiglia)\n",
    "Node2Vec introduce una passeggiata casuale parametrica del secondo ordine. Non si muove puramente a caso, ma è guidata da due parametri:\n",
    "* $p$ (Return parameter): Probabilità di tornare al nodo precedente (favorisce la struttura locale, simile a BFS).\n",
    "* $q$ (In-out parameter): Probabilità di allontanarsi (favorisce l'esplorazione globale, simile a DFS).\n",
    "\n",
    "#### Implementazione CPU (Libreria node2vec)\n",
    "* Logica: La CPU pre-calcola le probabilità di transizione per ogni nodo (o le calcola al volo) e simula sequenzialmente le camminate.\n",
    "* Il Problema: Python è un linguaggio interpretato e single-threaded (per via del GIL). Anche usando il multiprocessing (workers=8), la generazione di camminate è un processo seriale per ogni core:\n",
    "    1. Sono al nodo A.\n",
    "    2. Guardo i vicini.\n",
    "    3. Estraggo un numero casuale.\n",
    "    4. Scelgo il nodo B.\n",
    "    5. Ripeto 80 volte.\n",
    "* Effetto su 350k nodi: Devi generare $350.000 \\times 10 = 3.500.000$ camminate. Questo richiede milioni di operazioni di accesso alla memoria e generazione di numeri casuali, saturando la cache della CPU.\n",
    "\n",
    "#### Implementazione GPU (PyTorch Geometric)\n",
    "* Logica: La GPU eccelle nel parallelismo SIMD (Single Instruction, Multiple Data). Invece di simulare una camminata alla volta, la GPU gestisce un batch di migliaia di camminate simultaneamente.\n",
    "* Vettorializzazione: PyTorch Geometric utilizza operazioni su tensori sparsi. La matrice di adiacenza è caricata in VRAM. Il campionamento del prossimo passo per 10.000 camminate avviene in un unico \"colpo\" di clock (o quasi) grazie ai CUDA cores.\n",
    "\n",
    "### Fase 2: Ottimizzazione (Skip-Gram con Negative Sampling)\n",
    "Una volta ottenute le sequenze (es. [A, B, C, D, ...]), l'obiettivo è massimizzare la probabilità di vedere il contesto (es. B, C) dato l'input (A).\n",
    "La funzione obiettivo (Loss) cerca di massimizzare il prodotto scalare tra nodi vicini e minimizzarlo tra nodi non connessi:$$J(\\theta) = - \\sum_{(u,v) \\in \\text{walks}} \\log(\\sigma(z_u \\cdot z_v)) - \\sum_{(u,k) \\in \\text{noise}} \\log(1 - \\sigma(z_u \\cdot z_k))$$\n",
    "\n",
    "#### Implementazione CPU (gensim Word2Vec)\n",
    "* Struttura: Usa gensim, che ha un backend ottimizzato in C.\n",
    "* Processo: Prende le camminate generate (salvate in RAM come liste di stringhe) e addestra il modello.\n",
    "* Limiti:\n",
    "    * Data Transfer: Le camminate devono essere passate da Python a C.\n",
    "    * Memoria: Mantenere 3.5 milioni di camminate in memoria (liste Python) occupa molta RAM.\n",
    "    * Calcolo: L'aggiornamento dei pesi avviene sulla CPU. Sebbene veloce, non può competere con le operazioni matriciali di una GPU.\n",
    "\n",
    "#### Implementazione GPU (PyTorch SparseAdam)\n",
    "* Struttura: Tutto avviene in un ciclo di training PyTorch.\n",
    "* Processo Dinamico (On-the-fly): A differenza della CPU, PyG spesso genera le camminate dentro il DataLoader ad ogni epoca o batch. Non c'è bisogno di pre-calcolare e salvare 3.5 milioni di sequenze in RAM.\n",
    "* Negative Sampling Efficiente: Per ogni coppia positiva (nodo reale nel cammino), la GPU estrae molto velocemente $k$ nodi casuali (negativi) e calcola il prodotto scalare tramite moltiplicazione di matrici massiva.\n",
    "* Sparse Updates: Poiché modifichiamo solo i vettori dei nodi coinvolti nel batch (pochi rispetto a 350k), si usa SparseAdam, un ottimizzatore che aggiorna solo le righe specifiche della matrice degli embeddings, risparmiando tempo di calcolo enorme.\n",
    "\n",
    "### Riassunto Comparativo\n",
    "| Caratteristica | Variante CPU (node2vec standard) | Variante GPU (PyTorch Geometric) |\n",
    "|-----------|-----------|-----------|\n",
    "| Generazione Walks  | Pre-elaborazione: Lenta, sequenziale, usa molta RAM per salvare le liste.  | On-the-fly: Veloce, parallela, basso consumo RAM (generata e consumata subito).  |\n",
    "| Gestione Memoria  | Richiede RAM di sistema per il grafo + tutte le camminate.  | Richiede VRAM (8GB) per il grafo e i batch correnti. Molto più efficiente.  |\n",
    "| Addestramento  | Word2Vec (Gensim/C). Ottimizzato ma limitato dai core CPU.  | SGD/Adam su Tensori CUDA. Parallelismo massivo.  |\n",
    "| Scalabilità  | Lineare rispetto al numero di nodi (molto lento sopra 100k nodi).  | Sub-lineare (grazie al batching massivo), scala benissimo su milioni di nodi.  |\n",
    "\n",
    "\n",
    "\n",
    "### Conclusione per il tuo caso\n",
    "Con 350k nodi e 1.1M archi, ti trovi esattamente nel punto in cui l'approccio CPU diventa frustrante (ore di attesa) e l'approccio GPU brilla (minuti). La tua RTX 4060 è perfetta per gestire la matrice sparsa di queste dimensioni, permettendo al DataLoader di PyTorch di saturare la banda passante della scheda video piuttosto che aspettare i calcoli sequenziali della CPU."
   ],
   "id": "39e98530ae09320a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-09T20:38:17.205069900Z",
     "start_time": "2026-01-09T20:38:15.371161200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import networkx as nx\n",
    "import pickle\n",
    "\n",
    "graph_path = \"../data/processed/amazon_graph.pickle\"\n",
    "with open(graph_path, \"rb\") as f:\n",
    "    G = pickle.load(f)"
   ],
   "id": "efd85b398d998301",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### CPU version",
   "id": "fb28aa8cbfb5a255"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import time\n",
    "import os\n",
    "from node2vec import Node2Vec"
   ],
   "id": "364bc9fabcdd1bc6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def get_node2vec_emb_CPU(G, embedding_dim=128, walk_length=80, window=10,\n",
    "                         walks_per_node=10, p=1, q=2,):\n",
    "\n",
    "    \"\"\"\n",
    "    Computes Node2Vec embeddings on the CPU using the standard `node2vec` library.\n",
    "\n",
    "    Args:\n",
    "        G (nx.Graph): Input NetworkX graph.\n",
    "        embedding_dim (int): Dimension of the output embedding vectors.\n",
    "        walk_length (int): Length of each random walk.\n",
    "        window (int): Window size for the skip-gram model.\n",
    "        walks_per_node (int): Number of random walks generated per node.\n",
    "        p (float): Return parameter (likelihood of returning to the immediate source).\n",
    "        q (float): In-out parameter (likelihood of moving away from the source).\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame containing 'ASIN' (original ID) and embedding columns.\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"Starting embeddings computation on CPU using node2vec library\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Model configuration\n",
    "    node2vec_model = Node2Vec(\n",
    "        G,\n",
    "        dimensions=embedding_dim,\n",
    "        walk_length=walk_length,\n",
    "        num_walks=walks_per_node,\n",
    "        workers=os.cpu_count(),\n",
    "        p=p,\n",
    "        q=q,\n",
    "        quiet=False\n",
    "    )\n",
    "\n",
    "    # Model training\n",
    "    # window: max nodes distance at which the algorith will try to predict relations\n",
    "    # min_count: will consider also nodes that appear only 1 time\n",
    "    model = node2vec_model.fit(window = window, min_count = 1, batch_words = 4)\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(f\"Tempo totale CPU: {end_time - start_time:.2f} secondi\")\n",
    "\n",
    "    # Output DataFrame building\n",
    "    df = pd.DataFrame(\n",
    "        index=model.wv.index_to_key,\n",
    "        data=model.wv.vectors\n",
    "    )\n",
    "\n",
    "    df.columns = [f\"emb_{i}\" for i in range(model.vector_size)]\n",
    "    df = df.reset_index() # push the index (ASIN) to be a standard column\n",
    "    df = df.rename(columns={'index': 'ASIN'}) # rename the \"index\" column\n",
    "\n",
    "    return df"
   ],
   "id": "dc0247b15864198c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### GPU version",
   "id": "3fc30b0946817542"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-09T20:38:27.038104900Z",
     "start_time": "2026-01-09T20:38:20.849428Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import time\n",
    "import os\n",
    "import torch\n",
    "from torch_geometric.nn import Node2Vec as torch_Node2Vec\n",
    "from torch_geometric.utils import from_networkx\n",
    "import pandas as pd"
   ],
   "id": "da34d3cb4225590",
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-01-09T20:38:27.887024800Z",
     "start_time": "2026-01-09T20:38:27.855854900Z"
    }
   },
   "source": [
    "def get_node2vec_emb_GPU(G, embedding_dim=128,\n",
    "                         walk_length=80, context_size=10, walks_per_node=10,\n",
    "                         p=1, q=2, epochs=100, patience=3, batch_size=128):\n",
    "    \"\"\"\n",
    "    Computes Node2Vec embeddings using GPU acceleration via PyTorch Geometric.\n",
    "\n",
    "    This function preprocesses the input graph (attribute clearing and integer relabeling),\n",
    "    trains the model using an Early Stopping mechanism and re-maps the resulting vectors to\n",
    "    the original node IDs.\n",
    "\n",
    "    Args:\n",
    "        G (nx.Graph): Input NetworkX graph.\n",
    "        embedding_dim (int): Dimension of the output embedding vectors.\n",
    "        walk_length (int): Length of each random walk.\n",
    "        context_size (int): Window size for the skip-gram model.\n",
    "        walks_per_node (int): Number of random walks generated per node.\n",
    "        p (float): Return parameter (likelihood of returning to the immediate source).\n",
    "        q (float): In-out parameter (likelihood of moving away from the source).\n",
    "        epochs (int): Maximum number of training epochs.\n",
    "        patience (int): Epochs to wait for loss improvement before early stopping.\n",
    "        batch_size (int): Number of nodes per training batch.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing the 'ASIN' (original node ID) and the\n",
    "                      corresponding embedding vectors.\n",
    "    \"\"\"\n",
    "\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    if device == 'cuda':\n",
    "        print(\"CUDA available, using PyTorch on GPU.\")\n",
    "    if device == 'cpu':\n",
    "        print(\"CUDA not available, using PyTorch on CPU.\")\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Remove attributes from the graph's nodes\n",
    "    G_clean = G.copy()\n",
    "    for n in G_clean.nodes():       # for each node's ID n in G_clean...\n",
    "        G_clean.nodes[n].clear()    # access to the attributes dictionary\n",
    "\n",
    "    # Create a graph copy with integer node's labels\n",
    "    nodes_list = list(G_clean.nodes())\n",
    "    node_mapping = {node: i for i, node in enumerate(nodes_list)}\n",
    "    reverse_mapping = {i: node for i, node in enumerate(nodes_list)}\n",
    "    G_int = nx.relabel_nodes(G_clean, node_mapping)\n",
    "\n",
    "    # Convert the graph to PyTorch Geometric's Data object\n",
    "    data = from_networkx(G_int)\n",
    "    data = data.to(device)\n",
    "\n",
    "    # Model configuration\n",
    "    model = torch_Node2Vec(\n",
    "        data.edge_index,\n",
    "        embedding_dim=embedding_dim,\n",
    "        walk_length=walk_length,\n",
    "        context_size=context_size,\n",
    "        walks_per_node=walks_per_node,\n",
    "        num_negative_samples=1,\n",
    "        p=p,\n",
    "        q=q,\n",
    "        sparse=True\n",
    "    ).to(device)\n",
    "\n",
    "    # Generates walks on-the-fly and set batches of 128 nodes\n",
    "    loader = model.loader(batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "\n",
    "    # set the appropriate optimizer since the matrix is sparse\n",
    "    optimizer = torch.optim.SparseAdam(list(model.parameters()), lr=0.01)\n",
    "\n",
    "    # Training\n",
    "    model.train()               # start training mode\n",
    "    best_loss = float('inf')    # + infinity\n",
    "    counter = 0\n",
    "\n",
    "    print(f\"Starting training\")\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "\n",
    "        # for each nodes batch, read the pair of positive random walks and negative random walks\n",
    "        for pos_rw, neg_rw in loader:\n",
    "            optimizer.zero_grad()\n",
    "            loss = model.loss(pos_rw.to(device), neg_rw.to(device))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch: {epoch+1:02d}, Loss: {total_loss / len(loader):.4f}\")\n",
    "\n",
    "        # Stopping logic\n",
    "        avg_loss = total_loss / len(loader)\n",
    "        if avg_loss < best_loss:\n",
    "            best_loss = avg_loss\n",
    "            counter = 0  # reset the counter since\n",
    "        else:\n",
    "            counter += 1\n",
    "            print(f\"   No improvement detected for {counter} epochs.\")\n",
    "\n",
    "        if counter >= patience:\n",
    "            print(f\"Stopping model training since there has been no improvement for {patience} epochs.\")\n",
    "            break\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(f\"Total GPU time: {end_time - start_time:.2f} s\")\n",
    "\n",
    "    # Embeddings extraction\n",
    "    model.eval()                    # stop training mode\n",
    "    with torch.no_grad():           # do not compute gradients\n",
    "        z = model().cpu().numpy()   # bring values to CPU\n",
    "\n",
    "    # Remap list index to the original node ID\n",
    "    emb_dict = {nodes_list[i]: z[i] for i in range(len(nodes_list))}\n",
    "    df = pd.DataFrame.from_dict(emb_dict, orient='index')\n",
    "\n",
    "    df.columns = [f\"emb_{i}\" for i in range(df.shape[1])]\n",
    "    df = df.reset_index() # push the index (ASIN) to be a standard column\n",
    "    df = df.rename(columns={'index': 'ASIN'}) # rename the \"index\" column\n",
    "\n",
    "    return df\n"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-09T21:53:05.676993700Z",
     "start_time": "2026-01-09T20:38:56.883226900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    embeddings = get_node2vec_emb_GPU(G)\n",
    "\n",
    "    print(f\"DataFrame dimensions: {embeddings.shape}\")\n",
    "    print(embeddings.head())\n",
    "\n",
    "    embeddings.to_csv(\n",
    "        '../data/processed/embeddings_p1_q2.csv',\n",
    "        index=False,         # Row index is not needed\n",
    "        float_format='%.6f',\n",
    "        chunksize=10000\n",
    "    )"
   ],
   "id": "d923bc78ed57e19f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available, using PyTorch on GPU.\n",
      "Starting training\n",
      "Epoch: 01, Loss: 1.8085\n",
      "Epoch: 02, Loss: 0.7733\n",
      "Epoch: 03, Loss: 0.7409\n",
      "Epoch: 04, Loss: 0.7287\n",
      "Epoch: 05, Loss: 0.7223\n",
      "Epoch: 06, Loss: 0.7189\n",
      "Epoch: 07, Loss: 0.7171\n",
      "Epoch: 08, Loss: 0.7162\n",
      "Epoch: 09, Loss: 0.7160\n",
      "Epoch: 10, Loss: 0.7159\n",
      "Epoch: 11, Loss: 0.7159\n",
      "   No improvement detected for 1 epochs.\n",
      "Epoch: 12, Loss: 0.7160\n",
      "   No improvement detected for 2 epochs.\n",
      "Epoch: 13, Loss: 0.7160\n",
      "   No improvement detected for 3 epochs.\n",
      "Epoch: 14, Loss: 0.7160\n",
      "   No improvement detected for 4 epochs.\n",
      "Epoch: 15, Loss: 0.7160\n",
      "   No improvement detected for 5 epochs.\n",
      "Stopping model training since there has been no improvement for 5 epochs.\n",
      "Total GPU time: 4331.63 s\n",
      "DataFrame dimensions: (334843, 129)\n",
      "         ASIN     emb_0     emb_1     emb_2     emb_3     emb_4     emb_5  \\\n",
      "0  0827229534 -0.039401  0.319984  0.147284 -0.009532  0.272835 -0.001497   \n",
      "1  0738700797 -0.084367 -0.033158  0.071312  0.463542  0.294667  0.372568   \n",
      "2  0842328327 -0.200147 -0.074771 -0.087528 -0.043276  0.022293 -0.093859   \n",
      "3  1577943082  0.014877 -0.008863 -0.170374 -0.356302  0.073383 -0.284318   \n",
      "4  0486220125 -0.083501 -0.019884 -0.118082  0.031206  0.080626 -0.005765   \n",
      "\n",
      "      emb_6     emb_7     emb_8  ...   emb_118   emb_119   emb_120   emb_121  \\\n",
      "0  0.153352 -0.207378 -0.183975  ...  0.081881 -0.115338 -0.032910 -0.150788   \n",
      "1 -0.331131  0.021473 -0.076870  ... -0.639531 -0.200339 -0.190223  0.060360   \n",
      "2  0.133483 -0.069090 -0.360008  ...  0.233975  0.130195 -0.013525  0.121875   \n",
      "3  0.000955  0.341354  0.066642  ...  0.273996 -0.070449  0.021338 -0.042039   \n",
      "4 -0.009929 -0.201525 -0.061848  ...  0.178167  0.111985 -0.295679  0.011061   \n",
      "\n",
      "    emb_122   emb_123   emb_124   emb_125   emb_126   emb_127  \n",
      "0  0.118194 -0.140970  0.233102  0.003224 -0.074887  0.041781  \n",
      "1 -0.026398 -0.017045 -0.027020  0.032294  0.485112 -0.385177  \n",
      "2 -0.025883 -0.060119 -0.010186 -0.201285  0.039958  0.162182  \n",
      "3  0.395966  0.000411  0.084225  0.013561 -0.279434  0.081551  \n",
      "4 -0.036937  0.091132 -0.007050 -0.229351 -0.307035  0.071440  \n",
      "\n",
      "[5 rows x 129 columns]\n"
     ]
    }
   ],
   "execution_count": 4
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
