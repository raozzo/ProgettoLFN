\documentclass{article}
\usepackage{graphicx} % Required for inserting images
\usepackage{hyperref}

\setlength{\parindent}{0pt} %%per tolgiere in√¨dentazione ad inizio di ogni nuovo paragrafo

%ho messo questo per cambaire fony
\usepackage[italian]{babel}
\babelfont{rm}{Noto Sans}

\usepackage{paralist}
\usepackage{enumitem}
%\usepackage[margin=1in]{geometry}


\usepackage[a4paper, top=2.5cm, bottom=2.5cm, left=2cm, right=2cm]{geometry}

%%\usepackage{titlesec}
%\titlespacing*{\subsection}{0pt}{1ex}{0.5ex}

\title{\textbf{Comparative analysis of structural, learned, and hybrid feature representations for graph clustering} \\ \smallskip \large Learning From Networks - Project Proposal}
\author{Leonardo Gusson, Luca Rao, Chiara Frizzarin}
%\date{}

\begin{document}


\maketitle

\section{Motivation} \label{sec:motivation}

This project aims at solving a question: is it possible to use a co-purchasing network to find out the actual categories of products considered? And which kind of features representation works better: structural, learned or hybrid?
%\smallskip
The analysis is based on the "Amazon product co-purchasing network metadata" which was collected back in 2006 by crawling Amazon website. 

\smallskip
From this dataset a directed graph $G=(V,A)$ is going to be built:
\begin{compactitem}
    \item \textbf{Nodes}: Each node $ v \in V $ represents a unique product in the Amazon dataset ($|V|=548,552$); 
    \item \textbf{Arcs}: An edge $(u,v) \in A$ exists if product $v$ is often co-purchased after $u$ ($|A|=1,788,725$).
\end{compactitem}
\medskip
Each node comes with a set of information following this format:
\begin{compactitem}
    \item \textbf{Id}: Product id (number 0, ..., 548551)
    \item \textbf{ASIN}: Amazon Standard Identification Number
    \item \textbf{title}: Name/title of the product
    \item \textbf{group}: Product group (Book, DVD, Video or Music)
    \item \textbf{salesrank}: Amazon Salesrank
    \item \textbf{similar}: number $n \in [0,5]$ of co-purchased products followed by a list of their ASINs  (people who buy X also buy Y) (e.g. 2 B0001500VS B000002WA3) 
    \item \textbf{categories}: Location in product category hierarchy to which the product belongs (separated by |, category id in [])
    \item \textbf{reviews}: Product review information: time, user id, rating, total number of votes on the review, total number of helpfulness votes (how many people found the review to be helpful)
\end{compactitem}
\smallskip
All this information and the dataset can be found at \href{https://snap.stanford.edu/data/amazon-meta.html}{Stanford Large Network Dataset Collection}

\section{Method} \label{sec:methods}

The objective of this project is to compare the effectiveness and performance of three different features sets to cluster a product co-purchasing graph, knowing that the number of clusters (i.e. product categories) is four.

\subsection{Structural + semantic features}

We are going to combine the following structural centrality scores in a feature vector:
\smallskip
\begin{compactitem}
    \item \textbf{PageRank} $p(v)$ allows us to calculate the popularity of each product, in terms of important products co-purchased with other important products.
    \item \textbf{Closeness Centrality} $c(v)$ measures the importance of a product in the graph in terms of "trendsetters", i.e. it measures the closeness of a node to the others.
    \item \textbf{Betweenness Centrality} $b(v)$ represents crucial information for discovering key products that introduce customers to new categories.
    \item \textbf{Clustering Coefficient} $cc(v)$ identifies how a product's neighbors are interconnected, indicating whether it belongs to specialized kits of products or connects different groups.
\end{compactitem}
\medskip
Then we compute a score $rw(v)$ analyzing the rating of the reviews, and a score $sr(v)$ based on the Amazon "salesrank",
thus obtaining for each node $v$ : $$ \vec{F}_{st}(v) = [p(v),c(v),b(v),cc(v),rw(v),sr(v)] $$


\subsection{Node embeddings}

As a second, parallel approach, we will move beyond single-score metrics and try to cluster the graph only using topological features through the use of \textbf{embeddings}:
$$\vec{E}(v) = [e_1, e_2, \dots, e_d]$$
where the dimension $d$ of the vector will be defined during the test phase (probably 64, 128 or 256).

\subsection{Hybrid Approach}
The two approaches described above % (Classical Centrality and Topological Embeddings) TOGLIAMO ?
are powerful but capture fundamentally different types of information. Each has "blind spots" that the other can cover: indeed, centrality scores are interpretable and capture global roles while graph embeddings are excellent at capturing local context and semantic similarity. A hybrid approach can leverages the strengths of both.

To tackle this we will construct a multi-dimensional feature vector, $\vec{F}(v)$, for each product $v$. This vector will serve as the input for downstream machine learning models.
All features will be normalized (e.g. using Min-Max scaling or Z-score standardization) to bring them into a common range. %TODO vedere cosa fare (magari teniamo solo z_score)

The vector for a product $v$ is defined as a concatenation of its feature sets:
$$ \vec{F}(v) = [ \vec{E}(v)^\frown \vec{F}_{st}(v)] $$


\section{Intended experiments} \label{sec:experiments}
\subsection{Implementation} 


Given the graph size, we will implement approximated versions of pagerank, closeness centrality, betweenness centrality and clustering coefficient ourselves.
On the other hand, the learned features vector $\vec{E}$ will be computed using the \emph{Node2Vec} algorithm, whose dimension $d$ will be defined during the implementation phase.

To identify the optimal node representation for clustering, we will conduct three independent experiments using K-means with $k=4$.
In the first approach we will tests the efficacy of classic, explicit graph metrics by feeding the standardized (e.g. using the Z-score) vector $\vec{F}_{st}$ into K-means.
In the second approach we will evaluate the learned representation by first applying a dimensionality reduction technique (e.g. PCA or UMAP) due to the high dimensionality of embedding vectors, and finally we will use the reduced vector as K-means (or one of its approximate versions) input.

The same pipeline will be applied to the hybrid feature vector.


\subsection{Machines used}
We have access to the following machine, we will use the fastest one:
\begin{compactitem}
    \item Macbook Air M2 (8Gb RAM)
    \item Laptop Intel Core Ultra 9 (32Gb RAM) 
    \item Intel Core i7-6600U (8 Gb RAM)
\end{compactitem}

\subsection{Experiments}
To evaluate the three distinct approaches, we will perform a quantitative comparison based on two criteria: clustering quality and computational efficiency. 
For quality, we will measure how well the resulting k-means clusters align with the four ground truth categories using evaluation metrics such as the ARI (Adjusted Rand Index) or the NMI (Normalized Mutual Information).
For efficiency, we will measure the total execution time required for each full pipeline. 

\newpage

\section{Additional details}

In this first part of the project we collaborated often in-person and came up with a proposal through out an equally-participated brainstorming.
We first looked at the suggested large networks and tried to think what we could have focused on and which techniques we could have applied.

After that we consulted Gemini for better understanding if our ideas were enough challenging, but still doable (and also for proof-reading).


The formalization and the writing of the project proposal were done in presence, similarly to the other phases, and the work split is not so rigorous because again we discussed and tried to write together. Anyway it can be stated that: 

\begin{itemize}[noitemsep, topsep=0pt, leftmargin=*, itemsep=2pt]
    \item \textbf{Chiara:} Developed the project motivation (Section~\ref{sec:motivation}) and led the dataset research and selection.
    \item \textbf{Luca:} Authored the core methodology (Section~\ref{sec:methods}).
    \item \textbf{Leonardo:} Designed the experimental setup and validation plan (Section~\ref{sec:experiments}).
\end{itemize}



\end{document}

